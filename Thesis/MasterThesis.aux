\relax 
\providecommand\hyper@newdestlabel[2]{}
\providecommand\HyperFirstAtBeginDocument{\AtBeginDocument}
\HyperFirstAtBeginDocument{\ifx\hyper@anchor\@undefined
\global\let\oldcontentsline\contentsline
\gdef\contentsline#1#2#3#4{\oldcontentsline{#1}{#2}{#3}}
\global\let\oldnewlabel\newlabel
\gdef\newlabel#1#2{\newlabelxx{#1}#2}
\gdef\newlabelxx#1#2#3#4#5#6{\oldnewlabel{#1}{{#2}{#3}}}
\AtEndDocument{\ifx\hyper@anchor\@undefined
\let\contentsline\oldcontentsline
\let\newlabel\oldnewlabel
\fi}
\fi}
\global\let\hyper@last\relax 
\gdef\HyperFirstAtBeginDocument#1{#1}
\providecommand\HyField@AuxAddToFields[1]{}
\providecommand\HyField@AuxAddToCoFields[2]{}
\@writefile{toc}{\contentsline {chapter}{\numberline {1}Introduction}{2}{chapter.1}\protected@file@percent }
\@writefile{lof}{\addvspace {10\p@ }}
\@writefile{lot}{\addvspace {10\p@ }}
\newlabel{introduction}{{1}{2}{Introduction}{chapter.1}{}}
\citation{grokking}
\@writefile{toc}{\contentsline {chapter}{\numberline {2}Preliminaries}{3}{chapter.2}\protected@file@percent }
\@writefile{lof}{\addvspace {10\p@ }}
\@writefile{lot}{\addvspace {10\p@ }}
\newlabel{preliminaries}{{2}{3}{Preliminaries}{chapter.2}{}}
\@writefile{toc}{\contentsline {section}{\numberline {2.1}Reinforcement learning}{3}{section.2.1}\protected@file@percent }
\newlabel{pl-rl}{{2.1}{3}{Reinforcement learning}{section.2.1}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {2.1.1}General overview}{3}{subsection.2.1.1}\protected@file@percent }
\citation{grokking}
\citation{grokking}
\citation{grokking}
\citation{grokking}
\@writefile{lof}{\contentsline {figure}{\numberline {2.1}{\ignorespaces The cycle of interaction between the environment and an agent in reinforcement learning.\relax }}{5}{figure.caption.2}\protected@file@percent }
\providecommand*\caption@xref[2]{\@setref\relax\@undefined{#1}}
\newlabel{fig:rl_cycle}{{2.1}{5}{The cycle of interaction between the environment and an agent in reinforcement learning.\relax }{figure.caption.2}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {2.2}{\ignorespaces Example of a Markov decision process (MDP).\relax }}{5}{figure.caption.3}\protected@file@percent }
\newlabel{fig:mdp}{{2.2}{5}{Example of a Markov decision process (MDP).\relax }{figure.caption.3}{}}
\newlabel{reward}{{2.1}{5}{General overview}{equation.2.1.1}{}}
\citation{grokking}
\citation{grokking}
\citation{grokking}
\citation{nn}
\citation{nn}
\@writefile{toc}{\contentsline {subsection}{\numberline {2.1.2}Artificial neural networks}{7}{subsection.2.1.2}\protected@file@percent }
\citation{nn}
\citation{qlearning}
\@writefile{lof}{\contentsline {figure}{\numberline {2.3}{\ignorespaces Example of a fully connected feedforward artificial neural network. For one node, example weights and activation function are shown.\relax }}{8}{figure.caption.4}\protected@file@percent }
\newlabel{fig:nn}{{2.3}{8}{Example of a fully connected feedforward artificial neural network. For one node, example weights and activation function are shown.\relax }{figure.caption.4}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {2.1.3}Double deep-q-network (DDQN)}{8}{subsection.2.1.3}\protected@file@percent }
\newlabel{pl-dqn}{{2.1.3}{8}{Double deep-q-network (DDQN)}{subsection.2.1.3}{}}
\citation{dqn}
\citation{ddqn}
\citation{AE_general}
\@writefile{toc}{\contentsline {section}{\numberline {2.2}State-space dimensionality reduction}{10}{section.2.2}\protected@file@percent }
\newlabel{pl-dimensionality}{{2.2}{10}{State-space dimensionality reduction}{section.2.2}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {2.2.1}Principal Component Analysis}{10}{subsection.2.2.1}\protected@file@percent }
\newlabel{pl-pca}{{2.2.1}{10}{Principal Component Analysis}{subsection.2.2.1}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {2.2.2}Autoencoder}{10}{subsection.2.2.2}\protected@file@percent }
\newlabel{pl-ae}{{2.2.2}{10}{Autoencoder}{subsection.2.2.2}{}}
\newlabel{enc}{{2.6}{10}{Autoencoder}{equation.2.2.6}{}}
\newlabel{dec}{{2.7}{10}{Autoencoder}{equation.2.2.7}{}}
\newlabel{encdec}{{2.8}{10}{Autoencoder}{equation.2.2.8}{}}
\citation{AE_general}
\@writefile{lof}{\contentsline {figure}{\numberline {2.4}{\ignorespaces The architecture of an autoencoder.\relax }}{11}{figure.caption.5}\protected@file@percent }
\newlabel{fig:AE_architecture}{{2.4}{11}{The architecture of an autoencoder.\relax }{figure.caption.5}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {2.2.3}DeepMDP}{11}{subsection.2.2.3}\protected@file@percent }
\newlabel{pl-deepmdp}{{2.2.3}{11}{DeepMDP}{subsection.2.2.3}{}}
\citation{blizzard}
\citation{pysc2}
\@writefile{toc}{\contentsline {chapter}{\numberline {3}Research}{12}{chapter.3}\protected@file@percent }
\@writefile{lof}{\addvspace {10\p@ }}
\@writefile{lot}{\addvspace {10\p@ }}
\newlabel{research}{{3}{12}{Research}{chapter.3}{}}
\@writefile{toc}{\contentsline {section}{\numberline {3.1}Method}{12}{section.3.1}\protected@file@percent }
\newlabel{research-method}{{3.1}{12}{Method}{section.3.1}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {3.1.1}Environment: Starcraft II}{12}{subsection.3.1.1}\protected@file@percent }
\newlabel{research-env}{{3.1.1}{12}{Environment: Starcraft II}{subsection.3.1.1}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {3.1}{\ignorespaces Screenshot of the minigame \emph  {MoveToBeacon} in \emph  {StarCraft II}.\relax }}{13}{figure.caption.6}\protected@file@percent }
\newlabel{fig:pysc2_SS}{{3.1}{13}{Screenshot of the minigame \emph {MoveToBeacon} in \emph {StarCraft II}.\relax }{figure.caption.6}{}}
\@writefile{tdo}{\contentsline {todo}{Is this correct? Or are there actually perhaps only 3 features or something?}{13}{section*.7}\protected@file@percent }
\pgfsyspdfmark {pgfid1}{24729786}{32388500}
\pgfsyspdfmark {pgfid4}{33621278}{32380192}
\pgfsyspdfmark {pgfid5}{35243294}{32135006}
\@writefile{tdo}{\contentsline {todo}{Is this a correct usage of state-space?}{13}{section*.8}\protected@file@percent }
\pgfsyspdfmark {pgfid6}{14986322}{25258180}
\pgfsyspdfmark {pgfid9}{33621278}{22865892}
\pgfsyspdfmark {pgfid10}{35243294}{22620706}
\@writefile{lof}{\contentsline {figure}{\numberline {3.2}{\ignorespaces A state observation received by the RL agent, for the StarCraft II minigame MoveToBeacon. The yellow cells represent one beacon; the blue cell represents the army unit controlled by the player; all other cells are empty.\relax }}{14}{figure.caption.9}\protected@file@percent }
\newlabel{fig:state_example}{{3.2}{14}{A state observation received by the RL agent, for the StarCraft II minigame MoveToBeacon. The yellow cells represent one beacon; the blue cell represents the army unit controlled by the player; all other cells are empty.\relax }{figure.caption.9}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {3.1.2}Experiments}{14}{subsection.3.1.2}\protected@file@percent }
\newlabel{research-exp}{{3.1.2}{14}{Experiments}{subsection.3.1.2}{}}
\@writefile{tdo}{\contentsline {todo}{Again, is this correct?}{14}{section*.10}\protected@file@percent }
\pgfsyspdfmark {pgfid11}{7750942}{19446734}
\pgfsyspdfmark {pgfid14}{33621278}{19460190}
\pgfsyspdfmark {pgfid15}{35243294}{19215004}
\@writefile{tdo}{\contentsline {todo}{I guess "online" is not strictly correct}{16}{section*.11}\protected@file@percent }
\pgfsyspdfmark {pgfid16}{7750942}{28024943}
\pgfsyspdfmark {pgfid19}{33621278}{28030924}
\pgfsyspdfmark {pgfid20}{35243294}{27785738}
\@writefile{toc}{\contentsline {section}{\numberline {3.2}Results}{17}{section.3.2}\protected@file@percent }
\newlabel{research-results}{{3.2}{17}{Results}{section.3.2}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {3.2.1}Research results}{17}{subsection.3.2.1}\protected@file@percent }
\newlabel{research-general-results}{{3.2.1}{17}{Research results}{subsection.3.2.1}{}}
\@writefile{tdo}{\contentsline {todo}{Todo: create figure of this.}{18}{section*.14}\protected@file@percent }
\pgfsyspdfmark {pgfid21}{7750942}{44060688}
\pgfsyspdfmark {pgfid24}{33621278}{44074144}
\pgfsyspdfmark {pgfid25}{35243294}{43828958}
\@writefile{toc}{\contentsline {subsection}{\numberline {3.2.2}Discussion}{18}{subsection.3.2.2}\protected@file@percent }
\newlabel{research-discussion}{{3.2.2}{18}{Discussion}{subsection.3.2.2}{}}
\@writefile{tdo}{\contentsline {todo}{Perhaps try this?}{18}{section*.16}\protected@file@percent }
\pgfsyspdfmark {pgfid26}{7750942}{20284598}
\pgfsyspdfmark {pgfid29}{33621278}{20298054}
\pgfsyspdfmark {pgfid30}{35243294}{20052868}
\@writefile{tdo}{\contentsline {todo}{Citing}{18}{section*.17}\protected@file@percent }
\pgfsyspdfmark {pgfid31}{14619365}{17610728}
\pgfsyspdfmark {pgfid34}{33621278}{17624184}
\pgfsyspdfmark {pgfid35}{35243294}{17378998}
\newlabel{fig:results-base}{{3.3a}{22}{Results for the vanilla agent.\relax }{figure.caption.12}{}}
\newlabel{sub@fig:results-base}{{a}{22}{Results for the vanilla agent.\relax }{figure.caption.12}{}}
\newlabel{fig:results-ae}{{3.3b}{22}{Results for the pre-trained autoencoder agent.\relax }{figure.caption.12}{}}
\newlabel{sub@fig:results-ae}{{b}{22}{Results for the pre-trained autoencoder agent.\relax }{figure.caption.12}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {3.3}{\ignorespaces Results of the different RL agents.\relax }}{22}{figure.caption.12}\protected@file@percent }
\newlabel{fig:results-online-ae}{{3.3c}{23}{Results for the online trained autoencoder agent.\relax }{figure.caption.13}{}}
\newlabel{sub@fig:results-online-ae}{{c}{23}{Results for the online trained autoencoder agent.\relax }{figure.caption.13}{}}
\newlabel{fig:results-deepmdp}{{3.3d}{23}{Results for the DeepMDP agent.\relax }{figure.caption.13}{}}
\newlabel{sub@fig:results-deepmdp}{{d}{23}{Results for the DeepMDP agent.\relax }{figure.caption.13}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {3.3}{\ignorespaces Results of the different RL agents(cont.).\relax }}{23}{figure.caption.13}\protected@file@percent }
\newlabel{fig:results-agents}{{3.3}{23}{Results of the different RL agents(cont.).\relax }{figure.caption.13}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {3.4}{\ignorespaces Losses per 25 observations for training the autoencoder on $240.000$ state observations.\relax }}{24}{figure.caption.15}\protected@file@percent }
\newlabel{fig:ae-loss}{{3.4}{24}{Losses per 25 observations for training the autoencoder on $240.000$ state observations.\relax }{figure.caption.15}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {3.5}{\ignorespaces Correlation matrix for the autoencoder used in the pre-trained autoencoder agent, based on $60.000$ state observations. The x-axis contains the features of the original observations, and the y-axis contains the features of the reduced state observations.\relax }}{24}{figure.caption.18}\protected@file@percent }
\newlabel{fig:ae-corr}{{3.5}{24}{Correlation matrix for the autoencoder used in the pre-trained autoencoder agent, based on $60.000$ state observations. The x-axis contains the features of the original observations, and the y-axis contains the features of the reduced state observations.\relax }{figure.caption.18}{}}
\newlabel{fig:ae-featuremap-original}{{3.6a}{25}{The original observation, i.e. the input for the autoencoder.\relax }{figure.caption.19}{}}
\newlabel{sub@fig:ae-featuremap-original}{{a}{25}{The original observation, i.e. the input for the autoencoder.\relax }{figure.caption.19}{}}
\newlabel{fig:ae-featuremap-layer1}{{3.6b}{25}{The feauture map of the first convoluational layer, showing the output of its $32$ channels.\relax }{figure.caption.19}{}}
\newlabel{sub@fig:ae-featuremap-layer1}{{b}{25}{The feauture map of the first convoluational layer, showing the output of its $32$ channels.\relax }{figure.caption.19}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {3.6}{\ignorespaces A feature map visualisation for the autoencoder used by the pre-trained autoencoder agent.\relax }}{25}{figure.caption.19}\protected@file@percent }
\newlabel{fig:ae-featuremap-layer2}{{3.6c}{26}{The feature map of the second convolutional layer, showing the output of its single channel. Since it has only one channel, this also corresponds to the output of the autoencoder.\relax }{figure.caption.20}{}}
\newlabel{sub@fig:ae-featuremap-layer2}{{c}{26}{The feature map of the second convolutional layer, showing the output of its single channel. Since it has only one channel, this also corresponds to the output of the autoencoder.\relax }{figure.caption.20}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {3.6}{\ignorespaces A feature map visualisation for the autoencoder used by the pre-trained autoencoder agent (cont.).\relax }}{26}{figure.caption.20}\protected@file@percent }
\newlabel{fig:ae-featuremap}{{3.6}{26}{A feature map visualisation for the autoencoder used by the pre-trained autoencoder agent (cont.).\relax }{figure.caption.20}{}}
\@writefile{toc}{\contentsline {chapter}{\numberline {4}Related Work}{27}{chapter.4}\protected@file@percent }
\@writefile{lof}{\addvspace {10\p@ }}
\@writefile{lot}{\addvspace {10\p@ }}
\newlabel{relatedwork}{{4}{27}{Related Work}{chapter.4}{}}
\bibstyle{plain}
\bibdata{bibliography}
\@writefile{toc}{\contentsline {chapter}{\numberline {5}Conclusions}{28}{chapter.5}\protected@file@percent }
\@writefile{lof}{\addvspace {10\p@ }}
\@writefile{lot}{\addvspace {10\p@ }}
\newlabel{conclusions}{{5}{28}{Conclusions}{chapter.5}{}}
\bibcite{blizzard}{1}
\bibcite{nn}{2}
\bibcite{AE_general}{3}
\bibcite{qlearning}{4}
\bibcite{dqn}{5}
\bibcite{grokking}{6}
\bibcite{ddqn}{7}
\bibcite{pysc2}{8}
\@writefile{toc}{\contentsline {chapter}{\numberline {A}Appendix}{30}{appendix.A}\protected@file@percent }
\@writefile{lof}{\addvspace {10\p@ }}
\@writefile{lot}{\addvspace {10\p@ }}
\newlabel{appendix}{{A}{30}{Appendix}{appendix.A}{}}
\@writefile{toc}{\contentsline {section}{\numberline {A.1}Rl agent architectures}{30}{section.A.1}\protected@file@percent }
\newlabel{appendix-agents}{{A.1}{30}{Rl agent architectures}{section.A.1}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {A.1.1}Vanilla agent}{30}{subsection.A.1.1}\protected@file@percent }
