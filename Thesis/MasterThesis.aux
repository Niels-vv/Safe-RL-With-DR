\relax 
\providecommand\hyper@newdestlabel[2]{}
\providecommand\HyperFirstAtBeginDocument{\AtBeginDocument}
\HyperFirstAtBeginDocument{\ifx\hyper@anchor\@undefined
\global\let\oldcontentsline\contentsline
\gdef\contentsline#1#2#3#4{\oldcontentsline{#1}{#2}{#3}}
\global\let\oldnewlabel\newlabel
\gdef\newlabel#1#2{\newlabelxx{#1}#2}
\gdef\newlabelxx#1#2#3#4#5#6{\oldnewlabel{#1}{{#2}{#3}}}
\AtEndDocument{\ifx\hyper@anchor\@undefined
\let\contentsline\oldcontentsline
\let\newlabel\oldnewlabel
\fi}
\fi}
\global\let\hyper@last\relax 
\gdef\HyperFirstAtBeginDocument#1{#1}
\providecommand\HyField@AuxAddToFields[1]{}
\providecommand\HyField@AuxAddToCoFields[2]{}
\citation{deeprl}
\citation{AE_2019}
\citation{rlfitting}
\citation{AE_2019}
\citation{AE_2016}
\citation{representation_overview}
\@writefile{toc}{\contentsline {chapter}{\numberline {1}Introduction}{3}{chapter.1}\protected@file@percent }
\@writefile{lof}{\addvspace {10\p@ }}
\@writefile{lot}{\addvspace {10\p@ }}
\newlabel{introduction}{{1}{3}{Introduction}{chapter.1}{}}
\@writefile{toc}{\contentsline {section}{\numberline {1.1}Problem statement}{3}{section.1.1}\protected@file@percent }
\@writefile{toc}{\contentsline {section}{\numberline {1.2}Research questions}{3}{section.1.2}\protected@file@percent }
\citation{ddqn}
\citation{pysc2}
\citation{pong}
\@writefile{toc}{\contentsline {section}{\numberline {1.3}Method, results, and possible benefits}{4}{section.1.3}\protected@file@percent }
\providecommand*\caption@xref[2]{\@setref\relax\@undefined{#1}}
\newlabel{fig:rl_training}{{1.1a}{6}{High-level overview of training a state-space dimensionality reduction component; used for training the PCA and autoencoder components.\relax }{figure.caption.2}{}}
\newlabel{sub@fig:rl_training}{{a}{6}{High-level overview of training a state-space dimensionality reduction component; used for training the PCA and autoencoder components.\relax }{figure.caption.2}{}}
\newlabel{fig:rl_cycle_dimred}{{1.1b}{6}{Overview of the general architecture of an RL agent using a state-space dimensionality reduction method, including the reduction methods used in our experiments. The learning algorithm used is DDQN.\relax }{figure.caption.2}{}}
\newlabel{sub@fig:rl_cycle_dimred}{{b}{6}{Overview of the general architecture of an RL agent using a state-space dimensionality reduction method, including the reduction methods used in our experiments. The learning algorithm used is DDQN.\relax }{figure.caption.2}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {1.1}{\ignorespaces Overview of the process of training the state-space dimensionality reduction components for PCA and autoencoders, and their usage in an RL agent\relax }}{6}{figure.caption.2}\protected@file@percent }
\@writefile{toc}{\contentsline {section}{\numberline {1.4}Paper structure}{6}{section.1.4}\protected@file@percent }
\citation{mario}
\citation{pca_curran}
\citation{pca_neural}
\citation{pca_bitzer}
\citation{pca_bitzer}
\citation{AE_2010}
\citation{ae_visual}
\citation{AE_2016}
\@writefile{toc}{\contentsline {chapter}{\numberline {2}Related work}{8}{chapter.2}\protected@file@percent }
\@writefile{lof}{\addvspace {10\p@ }}
\@writefile{lot}{\addvspace {10\p@ }}
\newlabel{relatedwork}{{2}{8}{Related work}{chapter.2}{}}
\citation{vae}
\citation{rl_vae}
\citation{es}
\citation{rl_vaetwo}
\citation{rl_carla}
\citation{carla}
\citation{AE_2019}
\citation{deepmdp}
\citation{proto}
\citation{noproto}
\citation{project_matrix}
\citation{priors}
\citation{prototypical}
\citation{representation_overview}
\citation{grokking}
\@writefile{toc}{\contentsline {chapter}{\numberline {3}Preliminaries}{11}{chapter.3}\protected@file@percent }
\@writefile{lof}{\addvspace {10\p@ }}
\@writefile{lot}{\addvspace {10\p@ }}
\newlabel{preliminaries}{{3}{11}{Preliminaries}{chapter.3}{}}
\@writefile{toc}{\contentsline {section}{\numberline {3.1}Reinforcement learning}{11}{section.3.1}\protected@file@percent }
\newlabel{pl-rl}{{3.1}{11}{Reinforcement learning}{section.3.1}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {3.1.1}General overview}{11}{subsection.3.1.1}\protected@file@percent }
\citation{grokking}
\@writefile{lof}{\contentsline {figure}{\numberline {3.1}{\ignorespaces The cycle of interaction between the environment and an agent in reinforcement learning.\relax }}{12}{figure.caption.3}\protected@file@percent }
\newlabel{fig:rl_cycle}{{3.1}{12}{The cycle of interaction between the environment and an agent in reinforcement learning.\relax }{figure.caption.3}{}}
\citation{grokking}
\citation{grokking}
\citation{grokking}
\@writefile{lof}{\contentsline {figure}{\numberline {3.2}{\ignorespaces Example of a Markov decision process (MDP).\relax }}{13}{figure.caption.4}\protected@file@percent }
\newlabel{fig:mdp}{{3.2}{13}{Example of a Markov decision process (MDP).\relax }{figure.caption.4}{}}
\newlabel{reward}{{3.1}{13}{General overview}{equation.3.1.1}{}}
\citation{grokking}
\citation{grokking}
\citation{grokking}
\citation{nn}
\citation{nn}
\citation{nn}
\@writefile{toc}{\contentsline {subsection}{\numberline {3.1.2}Artificial neural networks}{15}{subsection.3.1.2}\protected@file@percent }
\newlabel{pl-nn}{{3.1.2}{15}{Artificial neural networks}{subsection.3.1.2}{}}
\citation{qlearning}
\@writefile{lof}{\contentsline {figure}{\numberline {3.3}{\ignorespaces A convolutional layer with a single filter. The filter convolves across the input image to produce one feature map. Adding more filters would result in a stack of feature maps (one per filter).\relax }}{16}{figure.caption.5}\protected@file@percent }
\newlabel{fig:cnn}{{3.3}{16}{A convolutional layer with a single filter. The filter convolves across the input image to produce one feature map. Adding more filters would result in a stack of feature maps (one per filter).\relax }{figure.caption.5}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {3.4}{\ignorespaces Example of a fully connected feedforward artificial neural network. For one node, example weights and activation function are shown.\relax }}{16}{figure.caption.6}\protected@file@percent }
\newlabel{fig:nn}{{3.4}{16}{Example of a fully connected feedforward artificial neural network. For one node, example weights and activation function are shown.\relax }{figure.caption.6}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {3.1.3}Double deep-q-network}{16}{subsection.3.1.3}\protected@file@percent }
\newlabel{pl-dqn}{{3.1.3}{16}{Double deep-q-network}{subsection.3.1.3}{}}
\citation{dqn}
\citation{ddqn}
\citation{grokking}
\citation{grokking}
\citation{grokking}
\citation{AE_2019}
\citation{AE_2019}
\citation{CNN_computation}
\citation{AE_2016}
\@writefile{lof}{\contentsline {figure}{\numberline {3.5}{\ignorespaces An overview of how a DDQN RL agent works.\relax }}{18}{figure.caption.7}\protected@file@percent }
\newlabel{fig:ddqn}{{3.5}{18}{An overview of how a DDQN RL agent works.\relax }{figure.caption.7}{}}
\@writefile{toc}{\contentsline {section}{\numberline {3.2}State-space dimensionality reduction}{18}{section.3.2}\protected@file@percent }
\newlabel{pl-dimensionality}{{3.2}{18}{State-space dimensionality reduction}{section.3.2}{}}
\citation{pca}
\@writefile{loa}{\contentsline {algorithm}{\numberline {1}{\ignorespaces DDQN training step \cite  [p.299]{grokking}.\relax }}{19}{algorithm.1}\protected@file@percent }
\newlabel{alg:ddqn}{{1}{19}{DDQN training step \cite [p.299]{grokking}.\relax }{algorithm.1}{}}
\citation{mario}
\citation{AE_general}
\@writefile{toc}{\contentsline {subsection}{\numberline {3.2.1}Principal Component Analysis}{20}{subsection.3.2.1}\protected@file@percent }
\newlabel{pl-pca}{{3.2.1}{20}{Principal Component Analysis}{subsection.3.2.1}{}}
\newlabel{eigenvectors}{{3.6}{20}{Principal Component Analysis}{equation.3.2.6}{}}
\citation{AE_general}
\citation{deepmdp}
\@writefile{toc}{\contentsline {subsection}{\numberline {3.2.2}Autoencoder}{21}{subsection.3.2.2}\protected@file@percent }
\newlabel{pl-ae}{{3.2.2}{21}{Autoencoder}{subsection.3.2.2}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {3.6}{\ignorespaces The architecture of an autoencoder.\relax }}{21}{figure.caption.8}\protected@file@percent }
\newlabel{fig:AE_architecture}{{3.6}{21}{The architecture of an autoencoder.\relax }{figure.caption.8}{}}
\newlabel{enc}{{3.7}{21}{Autoencoder}{equation.3.2.7}{}}
\newlabel{dec}{{3.8}{21}{Autoencoder}{equation.3.2.8}{}}
\newlabel{encdec}{{3.9}{21}{Autoencoder}{equation.3.2.9}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {3.2.3}DeepMDP}{21}{subsection.3.2.3}\protected@file@percent }
\newlabel{pl-deepmdp}{{3.2.3}{21}{DeepMDP}{subsection.3.2.3}{}}
\citation{deepmdp}
\citation{wgan}
\@writefile{lof}{\contentsline {figure}{\numberline {3.7}{\ignorespaces An overview of how a DeepMDP agent works.\relax }}{22}{figure.caption.9}\protected@file@percent }
\newlabel{fig:deepmdp_agent}{{3.7}{22}{An overview of how a DeepMDP agent works.\relax }{figure.caption.9}{}}
\@writefile{toc}{\contentsline {chapter}{\numberline {4}Research}{24}{chapter.4}\protected@file@percent }
\@writefile{lof}{\addvspace {10\p@ }}
\@writefile{lot}{\addvspace {10\p@ }}
\newlabel{research}{{4}{24}{Research}{chapter.4}{}}
\@writefile{toc}{\contentsline {section}{\numberline {4.1}Methodology}{24}{section.4.1}\protected@file@percent }
\newlabel{research-method}{{4.1}{24}{Methodology}{section.4.1}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {4.1.1}Experiments}{24}{subsection.4.1.1}\protected@file@percent }
\newlabel{research-exp}{{4.1.1}{24}{Experiments}{subsection.4.1.1}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {4.1}{\ignorespaces Overview of the general architecture of an RL agent using a state-space dimensionality reduction method, including the reduction methods used in our experiments. The learning algorithm used is DDQN.\relax }}{25}{figure.caption.10}\protected@file@percent }
\newlabel{fig:rl_cycle_dim}{{4.1}{25}{Overview of the general architecture of an RL agent using a state-space dimensionality reduction method, including the reduction methods used in our experiments. The learning algorithm used is DDQN.\relax }{figure.caption.10}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {4.2}{\ignorespaces Overview of the baseline agent, using DDQN.\relax }}{25}{figure.caption.11}\protected@file@percent }
\newlabel{fig:rl_cycle_base}{{4.2}{25}{Overview of the baseline agent, using DDQN.\relax }{figure.caption.11}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {4.3}{\ignorespaces Overview of the PCA agent.\relax }}{26}{figure.caption.12}\protected@file@percent }
\newlabel{fig:rl_cycle_pca}{{4.3}{26}{Overview of the PCA agent.\relax }{figure.caption.12}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {4.4}{\ignorespaces Overview of the pre-trained and online trained autoencoder agents.\relax }}{26}{figure.caption.13}\protected@file@percent }
\newlabel{fig:rl_cycle_ae}{{4.4}{26}{Overview of the pre-trained and online trained autoencoder agents.\relax }{figure.caption.13}{}}
\citation{blizzard}
\citation{pysc2}
\@writefile{toc}{\contentsline {subsection}{\numberline {4.1.2}Environment: Starcraft II}{27}{subsection.4.1.2}\protected@file@percent }
\newlabel{research-env-pysc2}{{4.1.2}{27}{Environment: Starcraft II}{subsection.4.1.2}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {4.5}{\ignorespaces Overview of the DeepMDP agent.\relax }}{28}{figure.caption.14}\protected@file@percent }
\newlabel{fig:rl_cycle_deepmdp}{{4.5}{28}{Overview of the DeepMDP agent.\relax }{figure.caption.14}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {4.6}{\ignorespaces Screenshot of the minigame \emph  {MoveToBeacon} in \emph  {StarCraft II}.\relax }}{28}{figure.caption.15}\protected@file@percent }
\newlabel{fig:pysc2_SS}{{4.6}{28}{Screenshot of the minigame \emph {MoveToBeacon} in \emph {StarCraft II}.\relax }{figure.caption.15}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {4.7}{\ignorespaces A state observation received by the RL agent, for the StarCraft II minigame MoveToBeacon. The yellow cells represent one beacon; the blue cell represents the army unit controlled by the player; all other cells are empty.\relax }}{29}{figure.caption.16}\protected@file@percent }
\newlabel{fig:state_example}{{4.7}{29}{A state observation received by the RL agent, for the StarCraft II minigame MoveToBeacon. The yellow cells represent one beacon; the blue cell represents the army unit controlled by the player; all other cells are empty.\relax }{figure.caption.16}{}}
\citation{transpose}
\citation{pong}
\@writefile{toc}{\contentsline {subsection}{\numberline {4.1.3}Environment: OpenAI Pong}{31}{subsection.4.1.3}\protected@file@percent }
\newlabel{research-env-pong}{{4.1.3}{31}{Environment: OpenAI Pong}{subsection.4.1.3}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {4.8}{\ignorespaces A screenshot from the OpenAI Gym Atari game Pong.\relax }}{31}{figure.caption.18}\protected@file@percent }
\newlabel{fig:pong-screen}{{4.8}{31}{A screenshot from the OpenAI Gym Atari game Pong.\relax }{figure.caption.18}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {4.9}{\ignorespaces A single observation in OpenAI Gym's Pong: four consecutive stacked frames.\relax }}{32}{figure.caption.19}\protected@file@percent }
\newlabel{fig:pong-obs}{{4.9}{32}{A single observation in OpenAI Gym's Pong: four consecutive stacked frames.\relax }{figure.caption.19}{}}
\citation{tsne}
\@writefile{toc}{\contentsline {subsection}{\numberline {4.1.4}Remarks on dimensionality reduction methods}{33}{subsection.4.1.4}\protected@file@percent }
\citation{maxvsconv}
\@writefile{toc}{\contentsline {section}{\numberline {4.2}Results}{34}{section.4.2}\protected@file@percent }
\newlabel{research-results}{{4.2}{34}{Results}{section.4.2}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {4.2.1}Research results: Starcraft II}{34}{subsection.4.2.1}\protected@file@percent }
\newlabel{research-results-pysc2}{{4.2.1}{34}{Research results: Starcraft II}{subsection.4.2.1}{}}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {4.2.1.1}Results overview}{34}{subsubsection.4.2.1.1}\protected@file@percent }
\@writefile{lof}{\contentsline {figure}{\numberline {4.10}{\ignorespaces The average score per 30 episodes for each RL agent in Starcraft II.\relax }}{35}{figure.caption.21}\protected@file@percent }
\newlabel{fig:results-pysc2-average}{{4.10}{35}{The average score per 30 episodes for each RL agent in Starcraft II.\relax }{figure.caption.21}{}}
\citation{pca_ae}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {4.2.1.2}Discussion}{36}{subsubsection.4.2.1.2}\protected@file@percent }
\newlabel{research-discussion-pysc2}{{4.2.1.2}{36}{Discussion}{subsubsection.4.2.1.2}{}}
\@writefile{toc}{\contentsline {paragraph}{\numberline {4.2.1.2.1}PCA Agent: losing all spatial information}{36}{paragraph.4.2.1.2.1}\protected@file@percent }
\@writefile{toc}{\contentsline {paragraph}{\numberline {4.2.1.2.2}Autoencoder agents analyses: outperforming baseline agent}{36}{paragraph.4.2.1.2.2}\protected@file@percent }
\newlabel{fig:pca-original}{{4.11a}{37}{The original observation, i.e. the input for the PCA transformation.\relax }{figure.caption.22}{}}
\newlabel{sub@fig:pca-original}{{a}{37}{The original observation, i.e. the input for the PCA transformation.\relax }{figure.caption.22}{}}
\newlabel{fig:pca-latent}{{4.11b}{37}{The latent representation given by the PCA transformation\relax }{figure.caption.22}{}}
\newlabel{sub@fig:pca-latent}{{b}{37}{The latent representation given by the PCA transformation\relax }{figure.caption.22}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {4.11}{\ignorespaces Latent representation of a state observation using PCA in Starcraft II.\relax }}{37}{figure.caption.22}\protected@file@percent }
\newlabel{fig:pca-state}{{4.11}{37}{Latent representation of a state observation using PCA in Starcraft II.\relax }{figure.caption.22}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {4.12}{\ignorespaces Losses per 25 observations for training the autoencoder on $240.000$ state observations.\relax }}{37}{figure.caption.23}\protected@file@percent }
\newlabel{fig:ae-loss}{{4.12}{37}{Losses per 25 observations for training the autoencoder on $240.000$ state observations.\relax }{figure.caption.23}{}}
\newlabel{fig:ae-featuremap-original}{{4.13a}{38}{The original observation, i.e. the input for the autoencoder.\relax }{figure.caption.24}{}}
\newlabel{sub@fig:ae-featuremap-original}{{a}{38}{The original observation, i.e. the input for the autoencoder.\relax }{figure.caption.24}{}}
\newlabel{fig:ae-featuremap-layer2}{{4.13b}{38}{The latent representation of the autoencoder, i.e. the output of the encoder.\relax }{figure.caption.24}{}}
\newlabel{sub@fig:ae-featuremap-layer2}{{b}{38}{The latent representation of the autoencoder, i.e. the output of the encoder.\relax }{figure.caption.24}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {4.13}{\ignorespaces The latent representation of the autoencoder.\relax }}{38}{figure.caption.24}\protected@file@percent }
\newlabel{fig:ae-featuremap}{{4.13}{38}{The latent representation of the autoencoder.\relax }{figure.caption.24}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {4.14}{\ignorespaces Process of creating a correlation matrix for the latent features with the original features, and creating the correlation matrix of a single latent feature with the original features.\relax }}{39}{figure.caption.25}\protected@file@percent }
\newlabel{fig:ae-corr-process}{{4.14}{39}{Process of creating a correlation matrix for the latent features with the original features, and creating the correlation matrix of a single latent feature with the original features.\relax }{figure.caption.25}{}}
\citation{deepmdp}
\@writefile{toc}{\contentsline {paragraph}{\numberline {4.2.1.2.3}DeepMDP agent: unable to balance multiple loss calculations}{40}{paragraph.4.2.1.2.3}\protected@file@percent }
\@writefile{lof}{\contentsline {figure}{\numberline {4.15}{\ignorespaces Correlation matrix for the autoencoder used in the pre-trained autoencoder agent, based on $60.000$ state observations. The x-axis contains the features of the reduced state observations, and the y-axis contains the features of the original observations.\relax }}{41}{figure.caption.26}\protected@file@percent }
\newlabel{fig:ae-corr}{{4.15}{41}{Correlation matrix for the autoencoder used in the pre-trained autoencoder agent, based on $60.000$ state observations. The x-axis contains the features of the reduced state observations, and the y-axis contains the features of the original observations.\relax }{figure.caption.26}{}}
\newlabel{fig:ae-latent-feature}{{4.16a}{42}{The latent feature that was used: at index $67$ of flattened grid data.\relax }{figure.caption.27}{}}
\newlabel{sub@fig:ae-latent-feature}{{a}{42}{The latent feature that was used: at index $67$ of flattened grid data.\relax }{figure.caption.27}{}}
\newlabel{fig:ae-latent-feature-corr-matrix}{{4.16b}{42}{Correlation matrix for latent feature $68$ with the original features.\relax }{figure.caption.27}{}}
\newlabel{sub@fig:ae-latent-feature-corr-matrix}{{b}{42}{Correlation matrix for latent feature $68$ with the original features.\relax }{figure.caption.27}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {4.16}{\ignorespaces The correlation matrix for latent feature $68$ with the original features.\relax }}{42}{figure.caption.27}\protected@file@percent }
\newlabel{fig:latent-feature-corr}{{4.16}{42}{The correlation matrix for latent feature $68$ with the original features.\relax }{figure.caption.27}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {4.2.2}Research results: OpenAI Pong}{43}{subsection.4.2.2}\protected@file@percent }
\newlabel{research-results-pong}{{4.2.2}{43}{Research results: OpenAI Pong}{subsection.4.2.2}{}}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {4.2.2.1}Results overview}{43}{subsubsection.4.2.2.1}\protected@file@percent }
\@writefile{lof}{\contentsline {figure}{\numberline {4.17}{\ignorespaces The average score per 30 episodes for each RL agent in Pong.\relax }}{43}{figure.caption.28}\protected@file@percent }
\newlabel{fig:results-pong-average}{{4.17}{43}{The average score per 30 episodes for each RL agent in Pong.\relax }{figure.caption.28}{}}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {4.2.2.2}Discussion}{45}{subsubsection.4.2.2.2}\protected@file@percent }
\newlabel{research-discussion-pong}{{4.2.2.2}{45}{Discussion}{subsubsection.4.2.2.2}{}}
\@writefile{toc}{\contentsline {paragraph}{\numberline {4.2.2.2.1}PCA agent: losing spatial information}{45}{paragraph.4.2.2.2.1}\protected@file@percent }
\newlabel{fig:pca-original-pong}{{4.18a}{45}{The original observation, i.e. the input for the PCA transformation.\relax }{figure.caption.29}{}}
\newlabel{sub@fig:pca-original-pong}{{a}{45}{The original observation, i.e. the input for the PCA transformation.\relax }{figure.caption.29}{}}
\newlabel{fig:pca-latent-pong}{{4.18b}{45}{The latent representation given by the PCA transformation\relax }{figure.caption.29}{}}
\newlabel{sub@fig:pca-latent-pong}{{b}{45}{The latent representation given by the PCA transformation\relax }{figure.caption.29}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {4.18}{\ignorespaces Latent representation of a state observation using PCA in Pong.\relax }}{45}{figure.caption.29}\protected@file@percent }
\newlabel{fig:pca-state-pong}{{4.18}{45}{Latent representation of a state observation using PCA in Pong.\relax }{figure.caption.29}{}}
\@writefile{toc}{\contentsline {paragraph}{\numberline {4.2.2.2.2}Pre-trained autoencoder agent: slightly worse than the baseline agent}{45}{paragraph.4.2.2.2.2}\protected@file@percent }
\@writefile{lof}{\contentsline {figure}{\numberline {4.19}{\ignorespaces Latent representation of the pre-trained autoencoder for an observation frame in Pong.\relax }}{46}{figure.caption.30}\protected@file@percent }
\newlabel{fig:ae-output-pong-pre}{{4.19}{46}{Latent representation of the pre-trained autoencoder for an observation frame in Pong.\relax }{figure.caption.30}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {4.20}{\ignorespaces Correlation matrix for the autoencoder used in the pre-trained autoencoder agent in Pong, based on $40.000$ state observations. The x-axis contains the features of the reduced state observations, and the y-axis contains the features of the original observations. Certain parts are zoomed into, revealing the correlation pattern.\relax }}{49}{figure.caption.31}\protected@file@percent }
\newlabel{fig:ae-corr-pong}{{4.20}{49}{Correlation matrix for the autoencoder used in the pre-trained autoencoder agent in Pong, based on $40.000$ state observations. The x-axis contains the features of the reduced state observations, and the y-axis contains the features of the original observations. Certain parts are zoomed into, revealing the correlation pattern.\relax }{figure.caption.31}{}}
\newlabel{fig:ae-latent-feature-pong}{{4.21a}{50}{The latent feature that was used: at index $903$ of flattened grid data.\relax }{figure.caption.32}{}}
\newlabel{sub@fig:ae-latent-feature-pong}{{a}{50}{The latent feature that was used: at index $903$ of flattened grid data.\relax }{figure.caption.32}{}}
\newlabel{fig:ae-latent-feature-corr-matrix-pong}{{4.21b}{50}{The correlation matrix for latent feature $904$ with the original features.\relax }{figure.caption.32}{}}
\newlabel{sub@fig:ae-latent-feature-corr-matrix-pong}{{b}{50}{The correlation matrix for latent feature $904$ with the original features.\relax }{figure.caption.32}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {4.21}{\ignorespaces The correlation matrix for latent feature $904$ with the original features.\relax }}{50}{figure.caption.32}\protected@file@percent }
\newlabel{fig:latent-feature-corr-pong}{{4.21}{50}{The correlation matrix for latent feature $904$ with the original features.\relax }{figure.caption.32}{}}
\newlabel{fig:ae-latent-feature-pong2}{{4.22a}{50}{The latent feature that was used: at index $917$ of flattened grid data.\relax }{figure.caption.33}{}}
\newlabel{sub@fig:ae-latent-feature-pong2}{{a}{50}{The latent feature that was used: at index $917$ of flattened grid data.\relax }{figure.caption.33}{}}
\newlabel{fig:ae-latent-feature-corr-matrix-pong2}{{4.22b}{50}{The correlation matrix for latent feature $918$ with the original features.\relax }{figure.caption.33}{}}
\newlabel{sub@fig:ae-latent-feature-corr-matrix-pong2}{{b}{50}{The correlation matrix for latent feature $918$ with the original features.\relax }{figure.caption.33}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {4.22}{\ignorespaces The correlation matrix for latent feature $918$ with the original features.\relax }}{50}{figure.caption.33}\protected@file@percent }
\newlabel{fig:latent-feature-corr-pong2}{{4.22}{50}{The correlation matrix for latent feature $918$ with the original features.\relax }{figure.caption.33}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {4.23}{\ignorespaces Losses per frame for training three autoencoders in Pong. Autoencoder 1 trained on $925.000$ frames to a loss of $0.3$, autoencoder 2 trained on $340.000$ frames to a loss of $0.9$, autoencoder 3 trained on $25.000$ frames to a loss of $30.7$ and autoencoder 4 trained on $10.000$ frames to a loss of $86.2$.\relax }}{51}{figure.caption.34}\protected@file@percent }
\newlabel{fig:ae-loss-pong}{{4.23}{51}{Losses per frame for training three autoencoders in Pong. Autoencoder 1 trained on $925.000$ frames to a loss of $0.3$, autoencoder 2 trained on $340.000$ frames to a loss of $0.9$, autoencoder 3 trained on $25.000$ frames to a loss of $30.7$ and autoencoder 4 trained on $10.000$ frames to a loss of $86.2$.\relax }{figure.caption.34}{}}
\newlabel{fig:ae-state-original-pong}{{4.24a}{52}{The original observation frame, i.e. the input for the autoencoder.\relax }{figure.caption.35}{}}
\newlabel{sub@fig:ae-state-original-pong}{{a}{52}{The original observation frame, i.e. the input for the autoencoder.\relax }{figure.caption.35}{}}
\newlabel{fig:ae1-state-pong}{{4.24b}{52}{The output of the encoder of autoencoder 2.\relax }{figure.caption.35}{}}
\newlabel{sub@fig:ae1-state-pong}{{b}{52}{The output of the encoder of autoencoder 2.\relax }{figure.caption.35}{}}
\newlabel{fig:ae2-state-pong}{{4.24c}{52}{The output of the encoder of autoencoder 3.\relax }{figure.caption.35}{}}
\newlabel{sub@fig:ae2-state-pong}{{c}{52}{The output of the encoder of autoencoder 3.\relax }{figure.caption.35}{}}
\newlabel{fig:ae3-state-pong}{{4.24d}{52}{The output of the encoder of autoencoder 4.\relax }{figure.caption.35}{}}
\newlabel{sub@fig:ae3-state-pong}{{d}{52}{The output of the encoder of autoencoder 4.\relax }{figure.caption.35}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {4.24}{\ignorespaces Latent representations of three different autoencoders for an observation frame in Pong. The more frames the autoencoder was trained, the more precise its latent representation is; from autoencoder 2 to autoencoder 4 the latent representations are increasingly less accurate.\relax }}{52}{figure.caption.35}\protected@file@percent }
\newlabel{fig:ae-output-pong}{{4.24}{52}{Latent representations of three different autoencoders for an observation frame in Pong. The more frames the autoencoder was trained, the more precise its latent representation is; from autoencoder 2 to autoencoder 4 the latent representations are increasingly less accurate.\relax }{figure.caption.35}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {4.25}{\ignorespaces Results for evaluating the pre-trained autoencoder agent while replacing its autoencoder.\relax }}{53}{figure.caption.36}\protected@file@percent }
\newlabel{fig:ae-evals}{{4.25}{53}{Results for evaluating the pre-trained autoencoder agent while replacing its autoencoder.\relax }{figure.caption.36}{}}
\newlabel{fig:ae1-results-pong}{{4.26a}{54}{Training results for RL agent using pre-trained autoencoder 1 in Pong.\relax }{figure.caption.37}{}}
\newlabel{sub@fig:ae1-results-pong}{{a}{54}{Training results for RL agent using pre-trained autoencoder 1 in Pong.\relax }{figure.caption.37}{}}
\newlabel{fig:ae2-results-pong}{{4.26b}{54}{Training results for RL agent using pre-trained autoencoder 2 in Pong.\relax }{figure.caption.37}{}}
\newlabel{sub@fig:ae2-results-pong}{{b}{54}{Training results for RL agent using pre-trained autoencoder 2 in Pong.\relax }{figure.caption.37}{}}
\newlabel{fig:ae3-results-pong}{{4.26c}{54}{Training results for RL agent using pre-trained autoencoder 3 in Pong.\relax }{figure.caption.37}{}}
\newlabel{sub@fig:ae3-results-pong}{{c}{54}{Training results for RL agent using pre-trained autoencoder 3 in Pong.\relax }{figure.caption.37}{}}
\newlabel{fig:ae4-results-pong}{{4.26d}{54}{Training results for RL agent using pre-trained autoencoder 4 in Pong.\relax }{figure.caption.37}{}}
\newlabel{sub@fig:ae4-results-pong}{{d}{54}{Training results for RL agent using pre-trained autoencoder 4 in Pong.\relax }{figure.caption.37}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {4.26}{\ignorespaces Training results for three different pre-trained autoencoder agents in Pong. Autoencoders 1 to 4 are trained to an increasing loss value (i.e. decreasing number of frames). Training to lower losses results in better latent representations, which result in better RL agents.\relax }}{54}{figure.caption.37}\protected@file@percent }
\newlabel{fig:ae-results-pong}{{4.26}{54}{Training results for three different pre-trained autoencoder agents in Pong. Autoencoders 1 to 4 are trained to an increasing loss value (i.e. decreasing number of frames). Training to lower losses results in better latent representations, which result in better RL agents.\relax }{figure.caption.37}{}}
\@writefile{toc}{\contentsline {paragraph}{\numberline {4.2.2.2.3}Online trained autoencoder agent: equaling the pre-trained autoencoder agent's policy}{55}{paragraph.4.2.2.2.3}\protected@file@percent }
\@writefile{lof}{\contentsline {figure}{\numberline {4.27}{\ignorespaces Latent representations of the pre-trained autoencoder and online trained autoencoder for an observation frame in Pong.\relax }}{56}{figure.caption.38}\protected@file@percent }
\newlabel{fig:online-ae-output-pong}{{4.27}{56}{Latent representations of the pre-trained autoencoder and online trained autoencoder for an observation frame in Pong.\relax }{figure.caption.38}{}}
\citation{mario}
\citation{deepmdp}
\@writefile{toc}{\contentsline {subsection}{\numberline {4.2.3}Results discussion}{57}{subsection.4.2.3}\protected@file@percent }
\newlabel{research-discussion}{{4.2.3}{57}{Results discussion}{subsection.4.2.3}{}}
\citation{mario}
\citation{deepmdp}
\@writefile{toc}{\contentsline {chapter}{\numberline {5}Conclusions and future research}{59}{chapter.5}\protected@file@percent }
\@writefile{lof}{\addvspace {10\p@ }}
\@writefile{lot}{\addvspace {10\p@ }}
\newlabel{conclusions}{{5}{59}{Conclusions and future research}{chapter.5}{}}
\bibstyle{plain}
\bibdata{bibliography}
\bibcite{pca_ae}{1}
\bibcite{es}{2}
\bibcite{pca_bitzer}{3}
\bibcite{blizzard}{4}
\bibcite{priors}{5}
\bibcite{pong}{6}
\bibcite{pca_curran}{7}
\bibcite{mario}{8}
\bibcite{carla}{9}
\bibcite{transpose}{10}
\bibcite{ae_visual}{11}
\bibcite{deepmdp}{12}
\bibcite{nn}{13}
\bibcite{wgan}{14}
\bibcite{rl_vae}{15}
\bibcite{gelu}{16}
\bibcite{AE_general}{17}
\bibcite{tsne}{18}
\bibcite{batchnorm}{19}
\bibcite{CNN_computation}{20}
\bibcite{qlearning}{21}
\bibcite{pca}{22}
\bibcite{rl_carla}{23}
\bibcite{vae}{24}
\bibcite{adam}{25}
\bibcite{AE_2010}{26}
\bibcite{rl_vaetwo}{27}
\bibcite{representation_overview}{28}
\bibcite{proto}{29}
\bibcite{noproto}{30}
\bibcite{deeprl}{31}
\bibcite{dqn}{32}
\bibcite{grokking}{33}
\bibcite{relu}{34}
\bibcite{l1}{35}
\bibcite{AE_2019}{36}
\bibcite{project_matrix}{37}
\bibcite{pca_neural}{38}
\bibcite{maxvsconv}{39}
\bibcite{ddqn}{40}
\bibcite{AE_2016}{41}
\bibcite{pysc2}{42}
\bibcite{prototypical}{43}
\bibcite{rlfitting}{44}
\citation{transpose}
\citation{relu}
\@writefile{toc}{\contentsline {chapter}{\numberline {A}Appendix}{65}{appendix.A}\protected@file@percent }
\@writefile{lof}{\addvspace {10\p@ }}
\@writefile{lot}{\addvspace {10\p@ }}
\newlabel{appendix}{{A}{65}{Appendix}{appendix.A}{}}
\@writefile{toc}{\contentsline {section}{\numberline {A.1}Starcraft II: RL agent architectures}{65}{section.A.1}\protected@file@percent }
\newlabel{appendix-agents}{{A.1}{65}{Starcraft II: RL agent architectures}{section.A.1}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {A.1.1}Baseline agent}{65}{subsection.A.1.1}\protected@file@percent }
\newlabel{appendix-baseline}{{A.1.1}{65}{Baseline agent}{subsection.A.1.1}{}}
\citation{adam}
\@writefile{lof}{\contentsline {figure}{\numberline {A.1}{\ignorespaces The decay of the epsilon value per episode.\relax }}{66}{figure.caption.40}\protected@file@percent }
\newlabel{fig:epsilon}{{A.1}{66}{The decay of the epsilon value per episode.\relax }{figure.caption.40}{}}
\citation{gelu}
\@writefile{toc}{\contentsline {subsection}{\numberline {A.1.2}PCA agent}{67}{subsection.A.1.2}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {A.1.3}Pre-trained and online trained autoencoder agent}{67}{subsection.A.1.3}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {A.1.4}DeepMDP agent}{67}{subsection.A.1.4}\protected@file@percent }
\citation{l1}
\citation{wgan}
\@writefile{toc}{\contentsline {subsection}{\numberline {A.1.5}Training results}{68}{subsection.A.1.5}\protected@file@percent }
\@writefile{toc}{\contentsline {section}{\numberline {A.2}OpenAI Pong: RL agent architectures}{68}{section.A.2}\protected@file@percent }
\newlabel{appendix-agents-pong}{{A.2}{68}{OpenAI Pong: RL agent architectures}{section.A.2}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {A.2.1}Baseline agent}{68}{subsection.A.2.1}\protected@file@percent }
\newlabel{appendix-baseline-pong}{{A.2.1}{68}{Baseline agent}{subsection.A.2.1}{}}
\newlabel{fig:results-base}{{A.2a}{69}{Results for the baseline agent.\relax }{figure.caption.41}{}}
\newlabel{sub@fig:results-base}{{a}{69}{Results for the baseline agent.\relax }{figure.caption.41}{}}
\newlabel{fig:results-pca}{{A.2b}{69}{Results for the PCA agent.\relax }{figure.caption.41}{}}
\newlabel{sub@fig:results-pca}{{b}{69}{Results for the PCA agent.\relax }{figure.caption.41}{}}
\newlabel{fig:results-ae}{{A.2c}{69}{Results for the pre-trained autoencoder agent.\relax }{figure.caption.41}{}}
\newlabel{sub@fig:results-ae}{{c}{69}{Results for the pre-trained autoencoder agent.\relax }{figure.caption.41}{}}
\newlabel{fig:results-online-ae}{{A.2d}{69}{Results for the online trained autoencoder agent.\relax }{figure.caption.41}{}}
\newlabel{sub@fig:results-online-ae}{{d}{69}{Results for the online trained autoencoder agent.\relax }{figure.caption.41}{}}
\newlabel{fig:results-deepmdp}{{A.2e}{69}{Results for the DeepMDP agent.\relax }{figure.caption.41}{}}
\newlabel{sub@fig:results-deepmdp}{{e}{69}{Results for the DeepMDP agent.\relax }{figure.caption.41}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {A.2}{\ignorespaces Results of the different RL agents in Starcraft II.\relax }}{69}{figure.caption.41}\protected@file@percent }
\newlabel{fig:results-agents}{{A.2}{69}{Results of the different RL agents in Starcraft II.\relax }{figure.caption.41}{}}
\citation{batchnorm}
\citation{relu}
\citation{adam}
\@writefile{toc}{\contentsline {subsection}{\numberline {A.2.2}PCA agent}{70}{subsection.A.2.2}\protected@file@percent }
\citation{gelu}
\@writefile{lof}{\contentsline {figure}{\numberline {A.3}{\ignorespaces The decay of the epsilon value per step in Pong.\relax }}{71}{figure.caption.42}\protected@file@percent }
\newlabel{fig:epsilon-pong}{{A.3}{71}{The decay of the epsilon value per step in Pong.\relax }{figure.caption.42}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {A.2.3}Pre-trained and online trained autoencoder agent}{71}{subsection.A.2.3}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {A.2.4}Training results}{72}{subsection.A.2.4}\protected@file@percent }
\newlabel{fig:results-base-pong}{{A.4a}{72}{Results for the baseline agent.\relax }{figure.caption.43}{}}
\newlabel{sub@fig:results-base-pong}{{a}{72}{Results for the baseline agent.\relax }{figure.caption.43}{}}
\newlabel{fig:results-pca-pong}{{A.4b}{72}{Results for the PCA agent.\relax }{figure.caption.43}{}}
\newlabel{sub@fig:results-pca-pong}{{b}{72}{Results for the PCA agent.\relax }{figure.caption.43}{}}
\newlabel{fig:results-ae-pong}{{A.4c}{72}{Results for the pre-trained autoencoder agent.\relax }{figure.caption.43}{}}
\newlabel{sub@fig:results-ae-pong}{{c}{72}{Results for the pre-trained autoencoder agent.\relax }{figure.caption.43}{}}
\newlabel{fig:results-online-ae-pong}{{A.4d}{72}{Results for the online trained autoencoder agent.\relax }{figure.caption.43}{}}
\newlabel{sub@fig:results-online-ae-pong}{{d}{72}{Results for the online trained autoencoder agent.\relax }{figure.caption.43}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {A.4}{\ignorespaces Results of the different RL agents in Pong.\relax }}{72}{figure.caption.43}\protected@file@percent }
\newlabel{fig:results-agents-pong}{{A.4}{72}{Results of the different RL agents in Pong.\relax }{figure.caption.43}{}}
