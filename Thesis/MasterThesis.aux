\relax 
\providecommand\hyper@newdestlabel[2]{}
\providecommand\HyperFirstAtBeginDocument{\AtBeginDocument}
\HyperFirstAtBeginDocument{\ifx\hyper@anchor\@undefined
\global\let\oldcontentsline\contentsline
\gdef\contentsline#1#2#3#4{\oldcontentsline{#1}{#2}{#3}}
\global\let\oldnewlabel\newlabel
\gdef\newlabel#1#2{\newlabelxx{#1}#2}
\gdef\newlabelxx#1#2#3#4#5#6{\oldnewlabel{#1}{{#2}{#3}}}
\AtEndDocument{\ifx\hyper@anchor\@undefined
\let\contentsline\oldcontentsline
\let\newlabel\oldnewlabel
\fi}
\fi}
\global\let\hyper@last\relax 
\gdef\HyperFirstAtBeginDocument#1{#1}
\providecommand\HyField@AuxAddToFields[1]{}
\providecommand\HyField@AuxAddToCoFields[2]{}
\@writefile{toc}{\contentsline {chapter}{\numberline {1}Introduction}{2}{chapter.1}\protected@file@percent }
\@writefile{lof}{\addvspace {10\p@ }}
\@writefile{lot}{\addvspace {10\p@ }}
\newlabel{introduction}{{1}{2}{Introduction}{chapter.1}{}}
\citation{grokking}
\@writefile{toc}{\contentsline {chapter}{\numberline {2}Preliminaries}{3}{chapter.2}\protected@file@percent }
\@writefile{lof}{\addvspace {10\p@ }}
\@writefile{lot}{\addvspace {10\p@ }}
\newlabel{preliminaries}{{2}{3}{Preliminaries}{chapter.2}{}}
\@writefile{toc}{\contentsline {section}{\numberline {2.1}Reinforcement learning}{3}{section.2.1}\protected@file@percent }
\newlabel{pl-rl}{{2.1}{3}{Reinforcement learning}{section.2.1}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {2.1.1}General overview}{3}{subsection.2.1.1}\protected@file@percent }
\citation{grokking}
\citation{grokking}
\citation{grokking}
\citation{grokking}
\@writefile{lof}{\contentsline {figure}{\numberline {2.1}{\ignorespaces The cycle of interaction between the environment and an agent in reinforcement learning.\relax }}{5}{figure.caption.2}\protected@file@percent }
\providecommand*\caption@xref[2]{\@setref\relax\@undefined{#1}}
\newlabel{fig:rl_cycle}{{2.1}{5}{The cycle of interaction between the environment and an agent in reinforcement learning.\relax }{figure.caption.2}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {2.2}{\ignorespaces Example of a Markov decision process (MDP).\relax }}{5}{figure.caption.3}\protected@file@percent }
\newlabel{fig:mdp}{{2.2}{5}{Example of a Markov decision process (MDP).\relax }{figure.caption.3}{}}
\newlabel{reward}{{2.1}{5}{General overview}{equation.2.1.1}{}}
\citation{grokking}
\citation{grokking}
\citation{grokking}
\citation{nn}
\citation{nn}
\@writefile{toc}{\contentsline {subsection}{\numberline {2.1.2}Artificial neural networks}{7}{subsection.2.1.2}\protected@file@percent }
\newlabel{pl-nn}{{2.1.2}{7}{Artificial neural networks}{subsection.2.1.2}{}}
\citation{nn}
\citation{qlearning}
\@writefile{lof}{\contentsline {figure}{\numberline {2.3}{\ignorespaces Example of a fully connected feedforward artificial neural network. For one node, example weights and activation function are shown.\relax }}{8}{figure.caption.4}\protected@file@percent }
\newlabel{fig:nn}{{2.3}{8}{Example of a fully connected feedforward artificial neural network. For one node, example weights and activation function are shown.\relax }{figure.caption.4}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {2.1.3}Double deep-q-network}{8}{subsection.2.1.3}\protected@file@percent }
\newlabel{pl-dqn}{{2.1.3}{8}{Double deep-q-network}{subsection.2.1.3}{}}
\citation{dqn}
\citation{ddqn}
\citation{grokking}
\citation{grokking}
\citation{grokking}
\citation{AE-2019}
\citation{AE_2019}
\citation{CNN_computation}
\citation{AE_2016}
\@writefile{loa}{\contentsline {algorithm}{\numberline {1}{\ignorespaces DDQN training step \cite  [p.299]{grokking}.\relax }}{10}{algorithm.1}\protected@file@percent }
\newlabel{alg:ddqn}{{1}{10}{DDQN training step \cite [p.299]{grokking}.\relax }{algorithm.1}{}}
\citation{pca}
\citation{mario}
\@writefile{toc}{\contentsline {section}{\numberline {2.2}State-space dimensionality reduction}{11}{section.2.2}\protected@file@percent }
\newlabel{pl-dimensionality}{{2.2}{11}{State-space dimensionality reduction}{section.2.2}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {2.2.1}Principal Component Analysis}{11}{subsection.2.2.1}\protected@file@percent }
\newlabel{pl-pca}{{2.2.1}{11}{Principal Component Analysis}{subsection.2.2.1}{}}
\citation{AE_general}
\newlabel{eigenvectors}{{2.6}{12}{Principal Component Analysis}{equation.2.2.6}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {2.2.2}Autoencoder}{12}{subsection.2.2.2}\protected@file@percent }
\newlabel{pl-ae}{{2.2.2}{12}{Autoencoder}{subsection.2.2.2}{}}
\citation{AE_general}
\@writefile{lof}{\contentsline {figure}{\numberline {2.4}{\ignorespaces The architecture of an autoencoder.\relax }}{13}{figure.caption.5}\protected@file@percent }
\newlabel{fig:AE_architecture}{{2.4}{13}{The architecture of an autoencoder.\relax }{figure.caption.5}{}}
\newlabel{enc}{{2.7}{13}{Autoencoder}{equation.2.2.7}{}}
\newlabel{dec}{{2.8}{13}{Autoencoder}{equation.2.2.8}{}}
\newlabel{encdec}{{2.9}{13}{Autoencoder}{equation.2.2.9}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {2.2.3}DeepMDP}{13}{subsection.2.2.3}\protected@file@percent }
\newlabel{pl-deepmdp}{{2.2.3}{13}{DeepMDP}{subsection.2.2.3}{}}
\@writefile{toc}{\contentsline {chapter}{\numberline {3}Research}{15}{chapter.3}\protected@file@percent }
\@writefile{lof}{\addvspace {10\p@ }}
\@writefile{lot}{\addvspace {10\p@ }}
\newlabel{research}{{3}{15}{Research}{chapter.3}{}}
\@writefile{toc}{\contentsline {section}{\numberline {3.1}Method}{15}{section.3.1}\protected@file@percent }
\newlabel{research-method}{{3.1}{15}{Method}{section.3.1}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {3.1.1}Experiments}{15}{subsection.3.1.1}\protected@file@percent }
\newlabel{research-exp}{{3.1.1}{15}{Experiments}{subsection.3.1.1}{}}
\citation{blizzard}
\citation{pysc2}
\@writefile{tdo}{\contentsline {todo}{I guess "online" is not strictly correct}{17}{section*.6}\protected@file@percent }
\pgfsyspdfmark {pgfid1}{7750942}{48524613}
\pgfsyspdfmark {pgfid4}{33621278}{48508830}
\pgfsyspdfmark {pgfid5}{35243294}{48263644}
\@writefile{toc}{\contentsline {subsection}{\numberline {3.1.2}Environment: Starcraft II}{17}{subsection.3.1.2}\protected@file@percent }
\newlabel{research-env-pysc2}{{3.1.2}{17}{Environment: Starcraft II}{subsection.3.1.2}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {3.1}{\ignorespaces Screenshot of the minigame \emph  {MoveToBeacon} in \emph  {StarCraft II}.\relax }}{18}{figure.caption.7}\protected@file@percent }
\newlabel{fig:pysc2_SS}{{3.1}{18}{Screenshot of the minigame \emph {MoveToBeacon} in \emph {StarCraft II}.\relax }{figure.caption.7}{}}
\@writefile{tdo}{\contentsline {todo}{Is this correct? Or are there actually perhaps only 3 features or something?}{18}{section*.8}\protected@file@percent }
\pgfsyspdfmark {pgfid6}{24729786}{31497210}
\pgfsyspdfmark {pgfid9}{33621278}{31510666}
\pgfsyspdfmark {pgfid10}{35243294}{31265480}
\@writefile{tdo}{\contentsline {todo}{Is this a correct usage of state-space?}{18}{section*.9}\protected@file@percent }
\pgfsyspdfmark {pgfid11}{14986322}{24366890}
\pgfsyspdfmark {pgfid14}{33621278}{21996366}
\pgfsyspdfmark {pgfid15}{35243294}{21751180}
\@writefile{lof}{\contentsline {figure}{\numberline {3.2}{\ignorespaces A state observation received by the RL agent, for the StarCraft II minigame MoveToBeacon. The yellow cells represent one beacon; the blue cell represents the army unit controlled by the player; all other cells are empty.\relax }}{19}{figure.caption.10}\protected@file@percent }
\newlabel{fig:state_example}{{3.2}{19}{A state observation received by the RL agent, for the StarCraft II minigame MoveToBeacon. The yellow cells represent one beacon; the blue cell represents the army unit controlled by the player; all other cells are empty.\relax }{figure.caption.10}{}}
\@writefile{toc}{\contentsline {subsubsection}{Agents setup}{19}{section*.11}\protected@file@percent }
\@writefile{tdo}{\contentsline {todo}{Again, is this correct?}{19}{section*.12}\protected@file@percent }
\pgfsyspdfmark {pgfid16}{29908662}{18442569}
\pgfsyspdfmark {pgfid19}{33621278}{18456025}
\pgfsyspdfmark {pgfid20}{35243294}{18210839}
\citation{transpose}
\@writefile{tdo}{\contentsline {todo}{I guess "online" is not strictly correct}{21}{section*.13}\protected@file@percent }
\pgfsyspdfmark {pgfid21}{7750942}{45850743}
\pgfsyspdfmark {pgfid24}{33621278}{45856724}
\pgfsyspdfmark {pgfid25}{35243294}{45611538}
\@writefile{toc}{\contentsline {subsection}{\numberline {3.1.3}Environment: OpenAI Pong}{21}{subsection.3.1.3}\protected@file@percent }
\newlabel{research-env-pong}{{3.1.3}{21}{Environment: OpenAI Pong}{subsection.3.1.3}{}}
\@writefile{toc}{\contentsline {subsubsection}{Agents setup}{21}{section*.14}\protected@file@percent }
\@writefile{toc}{\contentsline {section}{\numberline {3.2}Results}{21}{section.3.2}\protected@file@percent }
\newlabel{research-results}{{3.2}{21}{Results}{section.3.2}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {3.2.1}Research results: Starcraft II}{22}{subsection.3.2.1}\protected@file@percent }
\newlabel{research-results-pysc2}{{3.2.1}{22}{Research results: Starcraft II}{subsection.3.2.1}{}}
\@writefile{toc}{\contentsline {subsubsection}{Discussion}{22}{section*.17}\protected@file@percent }
\newlabel{research-discussion-pysc2}{{3.2.1}{22}{Discussion}{section*.17}{}}
\@writefile{tdo}{\contentsline {todo}{Citing}{22}{section*.18}\protected@file@percent }
\pgfsyspdfmark {pgfid26}{30367142}{10934451}
\pgfsyspdfmark {pgfid29}{33621278}{10947907}
\pgfsyspdfmark {pgfid30}{35243294}{10702721}
\@writefile{toc}{\contentsline {subsection}{\numberline {3.2.2}Research results: OpenAI Pong}{26}{subsection.3.2.2}\protected@file@percent }
\newlabel{research-results-pong}{{3.2.2}{26}{Research results: OpenAI Pong}{subsection.3.2.2}{}}
\@writefile{toc}{\contentsline {subsubsection}{Discussion}{26}{section*.26}\protected@file@percent }
\newlabel{research-discussion-pong}{{3.2.2}{26}{Discussion}{section*.26}{}}
\@writefile{tdo}{\contentsline {todo}{Citing, same as in pysc2}{27}{section*.27}\protected@file@percent }
\pgfsyspdfmark {pgfid31}{31144563}{44060688}
\pgfsyspdfmark {pgfid34}{33621278}{44074144}
\pgfsyspdfmark {pgfid35}{35243294}{43828958}
\@writefile{toc}{\contentsline {subsection}{\numberline {3.2.3}Results discussion}{28}{subsection.3.2.3}\protected@file@percent }
\newlabel{research-discussion}{{3.2.3}{28}{Results discussion}{subsection.3.2.3}{}}
\newlabel{fig:results-base}{{3.3a}{29}{Results for the baseline agent.\relax }{figure.caption.15}{}}
\newlabel{sub@fig:results-base}{{a}{29}{Results for the baseline agent.\relax }{figure.caption.15}{}}
\newlabel{fig:results-pca}{{3.3b}{29}{Results for the PCA agent using a scalar.\relax }{figure.caption.15}{}}
\newlabel{sub@fig:results-pca}{{b}{29}{Results for the PCA agent using a scalar.\relax }{figure.caption.15}{}}
\newlabel{fig:results-ae}{{3.3c}{29}{Results for the pre-trained autoencoder agent.\relax }{figure.caption.15}{}}
\newlabel{sub@fig:results-ae}{{c}{29}{Results for the pre-trained autoencoder agent.\relax }{figure.caption.15}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {3.3}{\ignorespaces Results of the different RL agents in Starcraft II.\relax }}{29}{figure.caption.15}\protected@file@percent }
\newlabel{fig:results-online-ae}{{3.3d}{30}{Results for the online trained autoencoder agent.\relax }{figure.caption.16}{}}
\newlabel{sub@fig:results-online-ae}{{d}{30}{Results for the online trained autoencoder agent.\relax }{figure.caption.16}{}}
\newlabel{fig:results-deepmdp}{{3.3e}{30}{Results for the DeepMDP agent.\relax }{figure.caption.16}{}}
\newlabel{sub@fig:results-deepmdp}{{e}{30}{Results for the DeepMDP agent.\relax }{figure.caption.16}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {3.3}{\ignorespaces Results of the different RL agents in Starcraft II(cont.).\relax }}{30}{figure.caption.16}\protected@file@percent }
\newlabel{fig:results-agents}{{3.3}{30}{Results of the different RL agents in Starcraft II(cont.).\relax }{figure.caption.16}{}}
\newlabel{fig:pca-original}{{3.4a}{31}{The original observation, i.e. the input for the PCA transformation.\relax }{figure.caption.19}{}}
\newlabel{sub@fig:pca-original}{{a}{31}{The original observation, i.e. the input for the PCA transformation.\relax }{figure.caption.19}{}}
\newlabel{fig:pca-latent}{{3.4b}{31}{The latent representation given by the PCA transformation\relax }{figure.caption.19}{}}
\newlabel{sub@fig:pca-latent}{{b}{31}{The latent representation given by the PCA transformation\relax }{figure.caption.19}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {3.4}{\ignorespaces Latent representation a state observation using PCA.\relax }}{31}{figure.caption.19}\protected@file@percent }
\newlabel{fig:pca-state}{{3.4}{31}{Latent representation a state observation using PCA.\relax }{figure.caption.19}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {3.5}{\ignorespaces Losses per 25 observations for training the autoencoder on $240.000$ state observations.\relax }}{32}{figure.caption.20}\protected@file@percent }
\newlabel{fig:ae-loss}{{3.5}{32}{Losses per 25 observations for training the autoencoder on $240.000$ state observations.\relax }{figure.caption.20}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {3.6}{\ignorespaces Correlation matrix for the autoencoder used in the pre-trained autoencoder agent, based on $60.000$ state observations. The x-axis contains the features of the original observations, and the y-axis contains the features of the reduced state observations.\relax }}{32}{figure.caption.21}\protected@file@percent }
\newlabel{fig:ae-corr}{{3.6}{32}{Correlation matrix for the autoencoder used in the pre-trained autoencoder agent, based on $60.000$ state observations. The x-axis contains the features of the original observations, and the y-axis contains the features of the reduced state observations.\relax }{figure.caption.21}{}}
\newlabel{fig:ae-featuremap-original}{{3.7a}{33}{The original observation, i.e. the input for the autoencoder.\relax }{figure.caption.22}{}}
\newlabel{sub@fig:ae-featuremap-original}{{a}{33}{The original observation, i.e. the input for the autoencoder.\relax }{figure.caption.22}{}}
\newlabel{fig:ae-featuremap-layer1}{{3.7b}{33}{The feauture map of the first convoluational layer, showing the output of its $32$ channels.\relax }{figure.caption.22}{}}
\newlabel{sub@fig:ae-featuremap-layer1}{{b}{33}{The feauture map of the first convoluational layer, showing the output of its $32$ channels.\relax }{figure.caption.22}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {3.7}{\ignorespaces A feature map visualisation for the autoencoder used by the pre-trained autoencoder agent.\relax }}{33}{figure.caption.22}\protected@file@percent }
\newlabel{fig:ae-featuremap-layer2}{{3.7c}{34}{The feature map of the second convolutional layer, showing the output of its single channel. Since it has only one channel, this also corresponds to the output of the autoencoder.\relax }{figure.caption.23}{}}
\newlabel{sub@fig:ae-featuremap-layer2}{{c}{34}{The feature map of the second convolutional layer, showing the output of its single channel. Since it has only one channel, this also corresponds to the output of the autoencoder.\relax }{figure.caption.23}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {3.7}{\ignorespaces A feature map visualisation for the autoencoder used by the pre-trained autoencoder agent (cont.).\relax }}{34}{figure.caption.23}\protected@file@percent }
\newlabel{fig:ae-featuremap}{{3.7}{34}{A feature map visualisation for the autoencoder used by the pre-trained autoencoder agent (cont.).\relax }{figure.caption.23}{}}
\newlabel{fig:results-base-pong}{{3.8a}{35}{Results for the baseline agent.\relax }{figure.caption.24}{}}
\newlabel{sub@fig:results-base-pong}{{a}{35}{Results for the baseline agent.\relax }{figure.caption.24}{}}
\newlabel{fig:results-pca-pong}{{3.8b}{35}{Results for the PCA agent using a scalar.\relax }{figure.caption.24}{}}
\newlabel{sub@fig:results-pca-pong}{{b}{35}{Results for the PCA agent using a scalar.\relax }{figure.caption.24}{}}
\newlabel{fig:results-ae-pong}{{3.8c}{35}{Results for the pre-trained autoencoder agent.\relax }{figure.caption.24}{}}
\newlabel{sub@fig:results-ae-pong}{{c}{35}{Results for the pre-trained autoencoder agent.\relax }{figure.caption.24}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {3.8}{\ignorespaces Results of the different RL agents in Pong.\relax }}{35}{figure.caption.24}\protected@file@percent }
\newlabel{fig:results-online-ae-pong}{{3.8d}{35}{Results for the online trained autoencoder agent.\relax }{figure.caption.25}{}}
\newlabel{sub@fig:results-online-ae-pong}{{d}{35}{Results for the online trained autoencoder agent.\relax }{figure.caption.25}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {3.8}{\ignorespaces Results of the different RL agents in Pong(cont.).\relax }}{35}{figure.caption.25}\protected@file@percent }
\newlabel{fig:results-agents-pong-pong}{{3.8}{35}{Results of the different RL agents in Pong(cont.).\relax }{figure.caption.25}{}}
\newlabel{fig:pca-original-pong}{{3.9a}{36}{The original observation, i.e. the input for the PCA transformation.\relax }{figure.caption.28}{}}
\newlabel{sub@fig:pca-original-pong}{{a}{36}{The original observation, i.e. the input for the PCA transformation.\relax }{figure.caption.28}{}}
\newlabel{fig:pca-latent-pong}{{3.9b}{36}{The latent representation given by the PCA transformation\relax }{figure.caption.28}{}}
\newlabel{sub@fig:pca-latent-pong}{{b}{36}{The latent representation given by the PCA transformation\relax }{figure.caption.28}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {3.9}{\ignorespaces Latent representation of a state observation using PCA.\relax }}{36}{figure.caption.28}\protected@file@percent }
\newlabel{fig:pca-state-pong}{{3.9}{36}{Latent representation of a state observation using PCA.\relax }{figure.caption.28}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {3.10}{\ignorespaces Losses per 25 observation frames for training three autoencoders in Pong. Autoencoder 1 trained on $332.000$ frames to a loss of $0.9$, autoencoder 2 trained on $25.000$ frames to a loss of $30.7$ and autoencoder 3 trained on $10.000$ frames to a loss of $86.2$.\relax }}{36}{figure.caption.29}\protected@file@percent }
\newlabel{fig:ae-loss-pong}{{3.10}{36}{Losses per 25 observation frames for training three autoencoders in Pong. Autoencoder 1 trained on $332.000$ frames to a loss of $0.9$, autoencoder 2 trained on $25.000$ frames to a loss of $30.7$ and autoencoder 3 trained on $10.000$ frames to a loss of $86.2$.\relax }{figure.caption.29}{}}
\newlabel{fig:ae-state-original-pong}{{3.11a}{37}{The original observation frame, i.e. the input for the autoencoder.\relax }{figure.caption.30}{}}
\newlabel{sub@fig:ae-state-original-pong}{{a}{37}{The original observation frame, i.e. the input for the autoencoder.\relax }{figure.caption.30}{}}
\newlabel{fig:ae1-state-pong}{{3.11b}{37}{The output of the encoder of autoencoder 1.\relax }{figure.caption.30}{}}
\newlabel{sub@fig:ae1-state-pong}{{b}{37}{The output of the encoder of autoencoder 1.\relax }{figure.caption.30}{}}
\newlabel{fig:ae2-state-pong}{{3.11c}{37}{The output of the encoder of autoencoder 2.\relax }{figure.caption.30}{}}
\newlabel{sub@fig:ae2-state-pong}{{c}{37}{The output of the encoder of autoencoder 2.\relax }{figure.caption.30}{}}
\newlabel{fig:ae3-state-pong}{{3.11d}{37}{The output of the encoder of autoencoder 3.\relax }{figure.caption.30}{}}
\newlabel{sub@fig:ae3-state-pong}{{d}{37}{The output of the encoder of autoencoder 3.\relax }{figure.caption.30}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {3.11}{\ignorespaces Latent representations of three different autoencoders for an observation frame in Pong.\relax }}{37}{figure.caption.30}\protected@file@percent }
\newlabel{fig:ae-output-pong}{{3.11}{37}{Latent representations of three different autoencoders for an observation frame in Pong.\relax }{figure.caption.30}{}}
\newlabel{fig:ae1-results-pong}{{3.12a}{38}{Training results for RL agent using pre-trained autoencoder 1 in Pong.\relax }{figure.caption.31}{}}
\newlabel{sub@fig:ae1-results-pong}{{a}{38}{Training results for RL agent using pre-trained autoencoder 1 in Pong.\relax }{figure.caption.31}{}}
\newlabel{fig:ae2-results-pong}{{3.12b}{38}{Training results for RL agent using pre-trained autoencoder 2 in Pong.\relax }{figure.caption.31}{}}
\newlabel{sub@fig:ae2-results-pong}{{b}{38}{Training results for RL agent using pre-trained autoencoder 2 in Pong.\relax }{figure.caption.31}{}}
\newlabel{fig:ae3-results-pong}{{3.12c}{38}{Training results for RL agent using pre-trained autoencoder 3 in Pong.\relax }{figure.caption.31}{}}
\newlabel{sub@fig:ae3-results-pong}{{c}{38}{Training results for RL agent using pre-trained autoencoder 3 in Pong.\relax }{figure.caption.31}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {3.12}{\ignorespaces Latent representations of three different autoencoders for an observation frame in Pong.\relax }}{38}{figure.caption.31}\protected@file@percent }
\newlabel{fig:ae-results-pong}{{3.12}{38}{Latent representations of three different autoencoders for an observation frame in Pong.\relax }{figure.caption.31}{}}
\citation{mario}
\citation{AE_2010}
\citation{AE_2016}
\citation{AE_2019}
\@writefile{toc}{\contentsline {chapter}{\numberline {4}Related work}{39}{chapter.4}\protected@file@percent }
\@writefile{lof}{\addvspace {10\p@ }}
\@writefile{lot}{\addvspace {10\p@ }}
\newlabel{relatedwork}{{4}{39}{Related work}{chapter.4}{}}
\citation{deepmdp}
\@writefile{toc}{\contentsline {chapter}{\numberline {5}Future work}{41}{chapter.5}\protected@file@percent }
\@writefile{lof}{\addvspace {10\p@ }}
\@writefile{lot}{\addvspace {10\p@ }}
\newlabel{futurework}{{5}{41}{Future work}{chapter.5}{}}
\bibstyle{plain}
\bibdata{bibliography}
\@writefile{toc}{\contentsline {chapter}{\numberline {6}Conclusions}{42}{chapter.6}\protected@file@percent }
\@writefile{lof}{\addvspace {10\p@ }}
\@writefile{lot}{\addvspace {10\p@ }}
\newlabel{conclusions}{{6}{42}{Conclusions}{chapter.6}{}}
\bibcite{blizzard}{1}
\bibcite{mario}{2}
\bibcite{transpose}{3}
\bibcite{deepmdp}{4}
\bibcite{nn}{5}
\bibcite{wgan}{6}
\bibcite{gelu}{7}
\bibcite{AE_general}{8}
\bibcite{CNN_computation}{9}
\bibcite{qlearning}{10}
\bibcite{pca}{11}
\bibcite{adam}{12}
\bibcite{AE_2010}{13}
\bibcite{dqn}{14}
\bibcite{grokking}{15}
\bibcite{relu}{16}
\bibcite{l1}{17}
\bibcite{AE_2019}{18}
\bibcite{ddqn}{19}
\bibcite{AE_2016}{20}
\bibcite{pysc2}{21}
\citation{transpose}
\citation{relu}
\@writefile{toc}{\contentsline {chapter}{\numberline {A}Appendix}{45}{appendix.A}\protected@file@percent }
\@writefile{lof}{\addvspace {10\p@ }}
\@writefile{lot}{\addvspace {10\p@ }}
\newlabel{appendix}{{A}{45}{Appendix}{appendix.A}{}}
\@writefile{toc}{\contentsline {section}{\numberline {A.1}RL agent architectures}{45}{section.A.1}\protected@file@percent }
\newlabel{appendix-agents}{{A.1}{45}{RL agent architectures}{section.A.1}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {A.1.1}Baseline agent}{45}{subsection.A.1.1}\protected@file@percent }
\newlabel{appendix-baseline}{{A.1.1}{45}{Baseline agent}{subsection.A.1.1}{}}
\citation{adam}
\@writefile{lof}{\contentsline {figure}{\numberline {A.1}{\ignorespaces The decay of the epsilon value per episode.\relax }}{46}{figure.caption.33}\protected@file@percent }
\newlabel{fig:epsilon}{{A.1}{46}{The decay of the epsilon value per episode.\relax }{figure.caption.33}{}}
\citation{gelu}
\@writefile{toc}{\contentsline {subsection}{\numberline {A.1.2}PCA agent}{47}{subsection.A.1.2}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {A.1.3}Pre-trained and online trained autoencoder agent}{47}{subsection.A.1.3}\protected@file@percent }
\citation{l1}
\citation{wgan}
\@writefile{toc}{\contentsline {subsection}{\numberline {A.1.4}DeepMDP agent}{48}{subsection.A.1.4}\protected@file@percent }
