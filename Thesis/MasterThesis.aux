\relax 
\providecommand\hyper@newdestlabel[2]{}
\providecommand\HyperFirstAtBeginDocument{\AtBeginDocument}
\HyperFirstAtBeginDocument{\ifx\hyper@anchor\@undefined
\global\let\oldcontentsline\contentsline
\gdef\contentsline#1#2#3#4{\oldcontentsline{#1}{#2}{#3}}
\global\let\oldnewlabel\newlabel
\gdef\newlabel#1#2{\newlabelxx{#1}#2}
\gdef\newlabelxx#1#2#3#4#5#6{\oldnewlabel{#1}{{#2}{#3}}}
\AtEndDocument{\ifx\hyper@anchor\@undefined
\let\contentsline\oldcontentsline
\let\newlabel\oldnewlabel
\fi}
\fi}
\global\let\hyper@last\relax 
\gdef\HyperFirstAtBeginDocument#1{#1}
\providecommand\HyField@AuxAddToFields[1]{}
\providecommand\HyField@AuxAddToCoFields[2]{}
\citation{deeprl}
\citation{AE_2019}
\citation{rlfitting}
\citation{AE_2019}
\citation{AE_2016}
\@writefile{toc}{\contentsline {chapter}{\numberline {1}Introduction}{3}{chapter.1}\protected@file@percent }
\@writefile{lof}{\addvspace {10\p@ }}
\@writefile{lot}{\addvspace {10\p@ }}
\newlabel{introduction}{{1}{3}{Introduction}{chapter.1}{}}
\@writefile{toc}{\contentsline {section}{\numberline {1.1}Problem statement}{3}{section.1.1}\protected@file@percent }
\@writefile{toc}{\contentsline {section}{\numberline {1.2}Research questions}{3}{section.1.2}\protected@file@percent }
\citation{ddqn}
\citation{pysc2}
\citation{pong}
\@writefile{toc}{\contentsline {section}{\numberline {1.3}Method, results and possible benefits}{4}{section.1.3}\protected@file@percent }
\@writefile{toc}{\contentsline {section}{\numberline {1.4}Paper structure}{5}{section.1.4}\protected@file@percent }
\citation{grokking}
\@writefile{toc}{\contentsline {chapter}{\numberline {2}Preliminaries}{7}{chapter.2}\protected@file@percent }
\@writefile{lof}{\addvspace {10\p@ }}
\@writefile{lot}{\addvspace {10\p@ }}
\newlabel{preliminaries}{{2}{7}{Preliminaries}{chapter.2}{}}
\@writefile{toc}{\contentsline {section}{\numberline {2.1}Reinforcement learning}{7}{section.2.1}\protected@file@percent }
\newlabel{pl-rl}{{2.1}{7}{Reinforcement learning}{section.2.1}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {2.1.1}General overview}{7}{subsection.2.1.1}\protected@file@percent }
\citation{grokking}
\citation{grokking}
\citation{grokking}
\newlabel{reward}{{2.1}{8}{General overview}{equation.2.1.1}{}}
\citation{grokking}
\@writefile{lof}{\contentsline {figure}{\numberline {2.1}{\ignorespaces The cycle of interaction between the environment and an agent in reinforcement learning.\relax }}{9}{figure.caption.2}\protected@file@percent }
\providecommand*\caption@xref[2]{\@setref\relax\@undefined{#1}}
\newlabel{fig:rl_cycle}{{2.1}{9}{The cycle of interaction between the environment and an agent in reinforcement learning.\relax }{figure.caption.2}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {2.2}{\ignorespaces Example of a Markov decision process (MDP).\relax }}{9}{figure.caption.3}\protected@file@percent }
\newlabel{fig:mdp}{{2.2}{9}{Example of a Markov decision process (MDP).\relax }{figure.caption.3}{}}
\citation{grokking}
\citation{grokking}
\citation{grokking}
\citation{nn}
\citation{nn}
\@writefile{toc}{\contentsline {subsection}{\numberline {2.1.2}Artificial neural networks}{10}{subsection.2.1.2}\protected@file@percent }
\newlabel{pl-nn}{{2.1.2}{10}{Artificial neural networks}{subsection.2.1.2}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {2.3}{\ignorespaces A convolutional layer with a single filter. The filter convolves across the input image to produce one feature map. Adding more filters would results in a stack of feature maps (one per filter).\relax }}{11}{figure.caption.4}\protected@file@percent }
\newlabel{fig:cnn}{{2.3}{11}{A convolutional layer with a single filter. The filter convolves across the input image to produce one feature map. Adding more filters would results in a stack of feature maps (one per filter).\relax }{figure.caption.4}{}}
\citation{nn}
\citation{qlearning}
\@writefile{lof}{\contentsline {figure}{\numberline {2.4}{\ignorespaces Example of a fully connected feedforward artificial neural network. For one node, example weights and activation function are shown.\relax }}{12}{figure.caption.5}\protected@file@percent }
\newlabel{fig:nn}{{2.4}{12}{Example of a fully connected feedforward artificial neural network. For one node, example weights and activation function are shown.\relax }{figure.caption.5}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {2.1.3}Double deep-q-network}{12}{subsection.2.1.3}\protected@file@percent }
\newlabel{pl-dqn}{{2.1.3}{12}{Double deep-q-network}{subsection.2.1.3}{}}
\citation{dqn}
\citation{ddqn}
\citation{grokking}
\citation{grokking}
\citation{grokking}
\citation{AE-2019}
\citation{AE_2019}
\citation{CNN_computation}
\citation{AE_2016}
\@writefile{lof}{\contentsline {figure}{\numberline {2.5}{\ignorespaces An overview of how a DDQN RL agent works.\relax }}{14}{figure.caption.6}\protected@file@percent }
\newlabel{fig:ddqn}{{2.5}{14}{An overview of how a DDQN RL agent works.\relax }{figure.caption.6}{}}
\@writefile{toc}{\contentsline {section}{\numberline {2.2}State-space dimensionality reduction}{14}{section.2.2}\protected@file@percent }
\newlabel{pl-dimensionality}{{2.2}{14}{State-space dimensionality reduction}{section.2.2}{}}
\citation{pca}
\citation{mario}
\@writefile{loa}{\contentsline {algorithm}{\numberline {1}{\ignorespaces DDQN training step \cite  [p.299]{grokking}.\relax }}{15}{algorithm.1}\protected@file@percent }
\newlabel{alg:ddqn}{{1}{15}{DDQN training step \cite [p.299]{grokking}.\relax }{algorithm.1}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {2.2.1}Principal Component Analysis}{15}{subsection.2.2.1}\protected@file@percent }
\newlabel{pl-pca}{{2.2.1}{15}{Principal Component Analysis}{subsection.2.2.1}{}}
\citation{AE_general}
\newlabel{eigenvectors}{{2.6}{16}{Principal Component Analysis}{equation.2.2.6}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {2.2.2}Autoencoder}{16}{subsection.2.2.2}\protected@file@percent }
\newlabel{pl-ae}{{2.2.2}{16}{Autoencoder}{subsection.2.2.2}{}}
\citation{AE_general}
\citation{deepmdp}
\citation{wgan}
\citation{deepmdp}
\@writefile{lof}{\contentsline {figure}{\numberline {2.6}{\ignorespaces The architecture of an autoencoder.\relax }}{17}{figure.caption.7}\protected@file@percent }
\newlabel{fig:AE_architecture}{{2.6}{17}{The architecture of an autoencoder.\relax }{figure.caption.7}{}}
\newlabel{enc}{{2.7}{17}{Autoencoder}{equation.2.2.7}{}}
\newlabel{dec}{{2.8}{17}{Autoencoder}{equation.2.2.8}{}}
\newlabel{encdec}{{2.9}{17}{Autoencoder}{equation.2.2.9}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {2.2.3}DeepMDP}{17}{subsection.2.2.3}\protected@file@percent }
\newlabel{pl-deepmdp}{{2.2.3}{17}{DeepMDP}{subsection.2.2.3}{}}
\citation{deepmdp}
\citation{wgan}
\@writefile{lof}{\contentsline {figure}{\numberline {2.7}{\ignorespaces An overview of how a DeepMDP agent works.\relax }}{18}{figure.caption.8}\protected@file@percent }
\newlabel{fig:deepmdp_agent}{{2.7}{18}{An overview of how a DeepMDP agent works.\relax }{figure.caption.8}{}}
\@writefile{toc}{\contentsline {chapter}{\numberline {3}Research}{19}{chapter.3}\protected@file@percent }
\@writefile{lof}{\addvspace {10\p@ }}
\@writefile{lot}{\addvspace {10\p@ }}
\newlabel{research}{{3}{19}{Research}{chapter.3}{}}
\@writefile{toc}{\contentsline {section}{\numberline {3.1}Methodology}{19}{section.3.1}\protected@file@percent }
\newlabel{research-method}{{3.1}{19}{Methodology}{section.3.1}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {3.1.1}Experiments}{19}{subsection.3.1.1}\protected@file@percent }
\newlabel{research-exp}{{3.1.1}{19}{Experiments}{subsection.3.1.1}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {3.1}{\ignorespaces Overview of the general architecture of an RL agent using a state-space dimensionality reduction method. In our experiments, the learning algorithm used is DDQN.\relax }}{20}{figure.caption.9}\protected@file@percent }
\newlabel{fig:rl_cycle_dim}{{3.1}{20}{Overview of the general architecture of an RL agent using a state-space dimensionality reduction method. In our experiments, the learning algorithm used is DDQN.\relax }{figure.caption.9}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {3.2}{\ignorespaces Overview of the baseline agent, using DDQN.\relax }}{21}{figure.caption.10}\protected@file@percent }
\newlabel{fig:rl_cycle_base}{{3.2}{21}{Overview of the baseline agent, using DDQN.\relax }{figure.caption.10}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {3.3}{\ignorespaces Overview of PCA agent.\relax }}{22}{figure.caption.11}\protected@file@percent }
\newlabel{fig:rl_cycle_pca}{{3.3}{22}{Overview of PCA agent.\relax }{figure.caption.11}{}}
\@writefile{tdo}{\contentsline {todo}{I guess "online" is not strictly correct}{22}{section*.13}\protected@file@percent }
\pgfsyspdfmark {pgfid1}{5873801}{15778020}
\pgfsyspdfmark {pgfid4}{35561850}{15784001}
\pgfsyspdfmark {pgfid5}{37183866}{15538815}
\@writefile{lof}{\contentsline {figure}{\numberline {3.4}{\ignorespaces Overview of the pre-trained and online trained autoencoder agents.\relax }}{23}{figure.caption.12}\protected@file@percent }
\newlabel{fig:rl_cycle_ae}{{3.4}{23}{Overview of the pre-trained and online trained autoencoder agents.\relax }{figure.caption.12}{}}
\citation{blizzard}
\citation{pysc2}
\@writefile{lof}{\contentsline {figure}{\numberline {3.5}{\ignorespaces Overview of the DeepMDP agent.\relax }}{24}{figure.caption.14}\protected@file@percent }
\newlabel{fig:rl_cycle_deepmdp}{{3.5}{24}{Overview of the DeepMDP agent.\relax }{figure.caption.14}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {3.1.2}Environment: Starcraft II}{24}{subsection.3.1.2}\protected@file@percent }
\newlabel{research-env-pysc2}{{3.1.2}{24}{Environment: Starcraft II}{subsection.3.1.2}{}}
\@writefile{tdo}{\contentsline {todo}{Is this correct? Or are there actually perhaps only 3 features or something?}{24}{section*.16}\protected@file@percent }
\pgfsyspdfmark {pgfid6}{19505330}{21801350}
\pgfsyspdfmark {pgfid9}{35561850}{21814806}
\pgfsyspdfmark {pgfid10}{37183866}{21569620}
\@writefile{tdo}{\contentsline {todo}{Is this a correct usage of state-space?}{24}{section*.17}\protected@file@percent }
\pgfsyspdfmark {pgfid11}{21775496}{15562320}
\pgfsyspdfmark {pgfid14}{35561850}{12300506}
\pgfsyspdfmark {pgfid15}{37183866}{12055320}
\@writefile{lof}{\contentsline {figure}{\numberline {3.6}{\ignorespaces Screenshot of the minigame \emph  {MoveToBeacon} in \emph  {StarCraft II}.\relax }}{25}{figure.caption.15}\protected@file@percent }
\newlabel{fig:pysc2_SS}{{3.6}{25}{Screenshot of the minigame \emph {MoveToBeacon} in \emph {StarCraft II}.\relax }{figure.caption.15}{}}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {3.1.2.1}Agents setup}{25}{subsubsection.3.1.2.1}\protected@file@percent }
\@writefile{tdo}{\contentsline {todo}{Again, is this correct?}{25}{section*.19}\protected@file@percent }
\pgfsyspdfmark {pgfid16}{19785661}{13621447}
\pgfsyspdfmark {pgfid19}{35561850}{13634903}
\pgfsyspdfmark {pgfid20}{37183866}{13389717}
\citation{transpose}
\@writefile{lof}{\contentsline {figure}{\numberline {3.7}{\ignorespaces A state observation received by the RL agent, for the StarCraft II minigame MoveToBeacon. The yellow cells represent one beacon; the blue cell represents the army unit controlled by the player; all other cells are empty.\relax }}{26}{figure.caption.18}\protected@file@percent }
\newlabel{fig:state_example}{{3.7}{26}{A state observation received by the RL agent, for the StarCraft II minigame MoveToBeacon. The yellow cells represent one beacon; the blue cell represents the army unit controlled by the player; all other cells are empty.\relax }{figure.caption.18}{}}
\citation{pong}
\@writefile{tdo}{\contentsline {todo}{I guess "online" is not strictly correct}{27}{section*.20}\protected@file@percent }
\pgfsyspdfmark {pgfid21}{5873801}{24459783}
\pgfsyspdfmark {pgfid24}{35561850}{24465764}
\pgfsyspdfmark {pgfid25}{37183866}{24220578}
\@writefile{toc}{\contentsline {subsection}{\numberline {3.1.3}Environment: OpenAI Pong}{28}{subsection.3.1.3}\protected@file@percent }
\newlabel{research-env-pong}{{3.1.3}{28}{Environment: OpenAI Pong}{subsection.3.1.3}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {3.8}{\ignorespaces A screenshot from the OpenAI Gym Atari game Pong.\relax }}{28}{figure.caption.21}\protected@file@percent }
\newlabel{fig:pong-screen}{{3.8}{28}{A screenshot from the OpenAI Gym Atari game Pong.\relax }{figure.caption.21}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {3.9}{\ignorespaces A single observation in OpenAI Gym's Pong: four consecutive stacked frames.\relax }}{29}{figure.caption.22}\protected@file@percent }
\newlabel{fig:pong-obs}{{3.9}{29}{A single observation in OpenAI Gym's Pong: four consecutive stacked frames.\relax }{figure.caption.22}{}}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {3.1.3.1}Agents setup}{29}{subsubsection.3.1.3.1}\protected@file@percent }
\citation{tsne}
\@writefile{tdo}{\contentsline {todo}{I guess "online" is not strictly correct}{30}{section*.23}\protected@file@percent }
\pgfsyspdfmark {pgfid26}{5873801}{24459783}
\pgfsyspdfmark {pgfid29}{35561850}{24465764}
\pgfsyspdfmark {pgfid30}{37183866}{24220578}
\@writefile{toc}{\contentsline {subsection}{\numberline {3.1.4}Remarks on method}{30}{subsection.3.1.4}\protected@file@percent }
\citation{maxvsconv}
\@writefile{toc}{\contentsline {section}{\numberline {3.2}Results}{31}{section.3.2}\protected@file@percent }
\newlabel{research-results}{{3.2}{31}{Results}{section.3.2}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {3.2.1}Research results: Starcraft II}{31}{subsection.3.2.1}\protected@file@percent }
\newlabel{research-results-pysc2}{{3.2.1}{31}{Research results: Starcraft II}{subsection.3.2.1}{}}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {3.2.1.1}Discussion}{32}{subsubsection.3.2.1.1}\protected@file@percent }
\newlabel{research-discussion-pysc2}{{3.2.1.1}{32}{Discussion}{subsubsection.3.2.1.1}{}}
\@writefile{toc}{\contentsline {paragraph}{\numberline {3.2.1.1.1}PCA Agent: losing all spatial information}{32}{paragraph.3.2.1.1.1}\protected@file@percent }
\@writefile{tdo}{\contentsline {todo}{Citing}{32}{section*.26}\protected@file@percent }
\pgfsyspdfmark {pgfid31}{14779559}{32521510}
\pgfsyspdfmark {pgfid34}{35561850}{32534966}
\pgfsyspdfmark {pgfid35}{37183866}{32289780}
\@writefile{toc}{\contentsline {paragraph}{\numberline {3.2.1.1.2}Autoencoder agents analyses: outperforming baseline agent}{32}{paragraph.3.2.1.1.2}\protected@file@percent }
\citation{deepmdp}
\@writefile{toc}{\contentsline {paragraph}{\numberline {3.2.1.1.3}DeepMDP agent: unable to balance multiple loss calculations}{34}{paragraph.3.2.1.1.3}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {3.2.2}Research results: OpenAI Pong}{35}{subsection.3.2.2}\protected@file@percent }
\newlabel{research-results-pong}{{3.2.2}{35}{Research results: OpenAI Pong}{subsection.3.2.2}{}}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {3.2.2.1}Discussion}{35}{subsubsection.3.2.2.1}\protected@file@percent }
\newlabel{research-discussion-pong}{{3.2.2.1}{35}{Discussion}{subsubsection.3.2.2.1}{}}
\@writefile{toc}{\contentsline {paragraph}{\numberline {3.2.2.1.1}PCA agent: losing spatial information}{35}{paragraph.3.2.2.1.1}\protected@file@percent }
\@writefile{tdo}{\contentsline {todo}{Citing, same as in pysc2}{36}{section*.35}\protected@file@percent }
\pgfsyspdfmark {pgfid36}{21348973}{46734558}
\pgfsyspdfmark {pgfid39}{35561850}{46748014}
\pgfsyspdfmark {pgfid40}{37183866}{46502828}
\@writefile{toc}{\contentsline {paragraph}{\numberline {3.2.2.1.2}Pre-trained autoencoder agent: slightly worse than the baseline agent}{36}{paragraph.3.2.2.1.2}\protected@file@percent }
\citation{mario}
\citation{deepmdp}
\@writefile{toc}{\contentsline {paragraph}{\numberline {3.2.2.1.3}Online trained autoencoder agent:}{37}{paragraph.3.2.2.1.3}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {3.2.3}Results discussion}{37}{subsection.3.2.3}\protected@file@percent }
\newlabel{research-discussion}{{3.2.3}{37}{Results discussion}{subsection.3.2.3}{}}
\newlabel{fig:results-base}{{3.10a}{39}{Results for the baseline agent.\relax }{figure.caption.24}{}}
\newlabel{sub@fig:results-base}{{a}{39}{Results for the baseline agent.\relax }{figure.caption.24}{}}
\newlabel{fig:results-pca}{{3.10b}{39}{Results for the PCA agent.\relax }{figure.caption.24}{}}
\newlabel{sub@fig:results-pca}{{b}{39}{Results for the PCA agent.\relax }{figure.caption.24}{}}
\newlabel{fig:results-ae}{{3.10c}{39}{Results for the pre-trained autoencoder agent.\relax }{figure.caption.24}{}}
\newlabel{sub@fig:results-ae}{{c}{39}{Results for the pre-trained autoencoder agent.\relax }{figure.caption.24}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {3.10}{\ignorespaces Results of the different RL agents in Starcraft II.\relax }}{39}{figure.caption.24}\protected@file@percent }
\newlabel{fig:results-online-ae}{{3.10d}{40}{Results for the online trained autoencoder agent.\relax }{figure.caption.25}{}}
\newlabel{sub@fig:results-online-ae}{{d}{40}{Results for the online trained autoencoder agent.\relax }{figure.caption.25}{}}
\newlabel{fig:results-deepmdp}{{3.10e}{40}{Results for the DeepMDP agent.\relax }{figure.caption.25}{}}
\newlabel{sub@fig:results-deepmdp}{{e}{40}{Results for the DeepMDP agent.\relax }{figure.caption.25}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {3.10}{\ignorespaces Results of the different RL agents in Starcraft II(cont.).\relax }}{40}{figure.caption.25}\protected@file@percent }
\newlabel{fig:results-agents}{{3.10}{40}{Results of the different RL agents in Starcraft II(cont.).\relax }{figure.caption.25}{}}
\newlabel{fig:pca-original}{{3.11a}{41}{The original observation, i.e. the input for the PCA transformation.\relax }{figure.caption.27}{}}
\newlabel{sub@fig:pca-original}{{a}{41}{The original observation, i.e. the input for the PCA transformation.\relax }{figure.caption.27}{}}
\newlabel{fig:pca-latent}{{3.11b}{41}{The latent representation given by the PCA transformation\relax }{figure.caption.27}{}}
\newlabel{sub@fig:pca-latent}{{b}{41}{The latent representation given by the PCA transformation\relax }{figure.caption.27}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {3.11}{\ignorespaces Latent representation a state observation using PCA.\relax }}{41}{figure.caption.27}\protected@file@percent }
\newlabel{fig:pca-state}{{3.11}{41}{Latent representation a state observation using PCA.\relax }{figure.caption.27}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {3.12}{\ignorespaces Losses per 25 observations for training the autoencoder on $240.000$ state observations.\relax }}{42}{figure.caption.28}\protected@file@percent }
\newlabel{fig:ae-loss}{{3.12}{42}{Losses per 25 observations for training the autoencoder on $240.000$ state observations.\relax }{figure.caption.28}{}}
\newlabel{fig:ae-featuremap-original}{{3.13a}{43}{The original observation, i.e. the input for the autoencoder.\relax }{figure.caption.29}{}}
\newlabel{sub@fig:ae-featuremap-original}{{a}{43}{The original observation, i.e. the input for the autoencoder.\relax }{figure.caption.29}{}}
\newlabel{fig:ae-featuremap-layer2}{{3.13b}{43}{The latent representation of the autoencoder, i.e. the output of the encoder.\relax }{figure.caption.29}{}}
\newlabel{sub@fig:ae-featuremap-layer2}{{b}{43}{The latent representation of the autoencoder, i.e. the output of the encoder.\relax }{figure.caption.29}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {3.13}{\ignorespaces The latent representation of the autoencoder.\relax }}{43}{figure.caption.29}\protected@file@percent }
\newlabel{fig:ae-featuremap}{{3.13}{43}{The latent representation of the autoencoder.\relax }{figure.caption.29}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {3.14}{\ignorespaces Process of creating a correlation matrix for the latent features with the original features, and creating the correlation matrix of a single latent feature with the original features.\relax }}{44}{figure.caption.30}\protected@file@percent }
\newlabel{fig:ae-corr-process}{{3.14}{44}{Process of creating a correlation matrix for the latent features with the original features, and creating the correlation matrix of a single latent feature with the original features.\relax }{figure.caption.30}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {3.15}{\ignorespaces Correlation matrix for the autoencoder used in the pre-trained autoencoder agent, based on $60.000$ state observations. The x-axis contains the features of the original observations, and the y-axis contains the features of the reduced state observations.\relax }}{44}{figure.caption.31}\protected@file@percent }
\newlabel{fig:ae-corr}{{3.15}{44}{Correlation matrix for the autoencoder used in the pre-trained autoencoder agent, based on $60.000$ state observations. The x-axis contains the features of the original observations, and the y-axis contains the features of the reduced state observations.\relax }{figure.caption.31}{}}
\newlabel{fig:ae-latent-feature}{{3.16a}{45}{The latent feature that was used.\relax }{figure.caption.32}{}}
\newlabel{sub@fig:ae-latent-feature}{{a}{45}{The latent feature that was used.\relax }{figure.caption.32}{}}
\newlabel{fig:ae-latent-feature-corr-matrix}{{3.16b}{45}{The feauture map of the first convoluational layer, showing the output of its $32$ channels.\relax }{figure.caption.32}{}}
\newlabel{sub@fig:ae-latent-feature-corr-matrix}{{b}{45}{The feauture map of the first convoluational layer, showing the output of its $32$ channels.\relax }{figure.caption.32}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {3.16}{\ignorespaces The correlation matrix for latent feature with the original features.\relax }}{45}{figure.caption.32}\protected@file@percent }
\newlabel{fig:latent-feature-corr}{{3.16}{45}{The correlation matrix for latent feature with the original features.\relax }{figure.caption.32}{}}
\newlabel{fig:results-base-pong}{{3.17a}{46}{Results for the baseline agent.\relax }{figure.caption.33}{}}
\newlabel{sub@fig:results-base-pong}{{a}{46}{Results for the baseline agent.\relax }{figure.caption.33}{}}
\newlabel{fig:results-pca-pong}{{3.17b}{46}{Results for the PCA agent.\relax }{figure.caption.33}{}}
\newlabel{sub@fig:results-pca-pong}{{b}{46}{Results for the PCA agent.\relax }{figure.caption.33}{}}
\newlabel{fig:results-ae-pong}{{3.17c}{46}{Results for the pre-trained autoencoder agent.\relax }{figure.caption.33}{}}
\newlabel{sub@fig:results-ae-pong}{{c}{46}{Results for the pre-trained autoencoder agent.\relax }{figure.caption.33}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {3.17}{\ignorespaces Results of the different RL agents in Pong.\relax }}{46}{figure.caption.33}\protected@file@percent }
\newlabel{fig:results-online-ae-pong}{{3.17d}{47}{Results for the online trained autoencoder agent.\relax }{figure.caption.34}{}}
\newlabel{sub@fig:results-online-ae-pong}{{d}{47}{Results for the online trained autoencoder agent.\relax }{figure.caption.34}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {3.17}{\ignorespaces Results of the different RL agents in Pong(cont.).\relax }}{47}{figure.caption.34}\protected@file@percent }
\newlabel{fig:results-agents-pong}{{3.17}{47}{Results of the different RL agents in Pong(cont.).\relax }{figure.caption.34}{}}
\newlabel{fig:pca-original-pong}{{3.18a}{48}{The original observation, i.e. the input for the PCA transformation.\relax }{figure.caption.36}{}}
\newlabel{sub@fig:pca-original-pong}{{a}{48}{The original observation, i.e. the input for the PCA transformation.\relax }{figure.caption.36}{}}
\newlabel{fig:pca-latent-pong}{{3.18b}{48}{The latent representation given by the PCA transformation\relax }{figure.caption.36}{}}
\newlabel{sub@fig:pca-latent-pong}{{b}{48}{The latent representation given by the PCA transformation\relax }{figure.caption.36}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {3.18}{\ignorespaces Latent representation of a state observation using PCA.\relax }}{48}{figure.caption.36}\protected@file@percent }
\newlabel{fig:pca-state-pong}{{3.18}{48}{Latent representation of a state observation using PCA.\relax }{figure.caption.36}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {3.19}{\ignorespaces Losses frame for training three autoencoders in Pong. Autoencoder 1 trained on $340.000$ frames to a loss of $0.9$, autoencoder 2 trained on $25.000$ frames to a loss of $30.7$ and autoencoder 3 trained on $10.000$ frames to a loss of $86.2$.\relax }}{49}{figure.caption.37}\protected@file@percent }
\newlabel{fig:ae-loss-pong}{{3.19}{49}{Losses frame for training three autoencoders in Pong. Autoencoder 1 trained on $340.000$ frames to a loss of $0.9$, autoencoder 2 trained on $25.000$ frames to a loss of $30.7$ and autoencoder 3 trained on $10.000$ frames to a loss of $86.2$.\relax }{figure.caption.37}{}}
\newlabel{fig:ae-state-original-pong}{{3.20a}{50}{The original observation frame, i.e. the input for the autoencoder.\relax }{figure.caption.38}{}}
\newlabel{sub@fig:ae-state-original-pong}{{a}{50}{The original observation frame, i.e. the input for the autoencoder.\relax }{figure.caption.38}{}}
\newlabel{fig:ae1-state-pong}{{3.20b}{50}{The output of the encoder of autoencoder 1.\relax }{figure.caption.38}{}}
\newlabel{sub@fig:ae1-state-pong}{{b}{50}{The output of the encoder of autoencoder 1.\relax }{figure.caption.38}{}}
\newlabel{fig:ae2-state-pong}{{3.20c}{50}{The output of the encoder of autoencoder 2.\relax }{figure.caption.38}{}}
\newlabel{sub@fig:ae2-state-pong}{{c}{50}{The output of the encoder of autoencoder 2.\relax }{figure.caption.38}{}}
\newlabel{fig:ae3-state-pong}{{3.20d}{50}{The output of the encoder of autoencoder 3.\relax }{figure.caption.38}{}}
\newlabel{sub@fig:ae3-state-pong}{{d}{50}{The output of the encoder of autoencoder 3.\relax }{figure.caption.38}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {3.20}{\ignorespaces Latent representations of three different autoencoders for an observation frame in Pong.\relax }}{50}{figure.caption.38}\protected@file@percent }
\newlabel{fig:ae-output-pong}{{3.20}{50}{Latent representations of three different autoencoders for an observation frame in Pong.\relax }{figure.caption.38}{}}
\newlabel{fig:ae1-results-pong}{{3.21a}{51}{Training results for RL agent using pre-trained autoencoder 1 in Pong.\relax }{figure.caption.39}{}}
\newlabel{sub@fig:ae1-results-pong}{{a}{51}{Training results for RL agent using pre-trained autoencoder 1 in Pong.\relax }{figure.caption.39}{}}
\newlabel{fig:ae2-results-pong}{{3.21b}{51}{Training results for RL agent using pre-trained autoencoder 2 in Pong.\relax }{figure.caption.39}{}}
\newlabel{sub@fig:ae2-results-pong}{{b}{51}{Training results for RL agent using pre-trained autoencoder 2 in Pong.\relax }{figure.caption.39}{}}
\newlabel{fig:ae3-results-pong}{{3.21c}{51}{Training results for RL agent using pre-trained autoencoder 3 in Pong.\relax }{figure.caption.39}{}}
\newlabel{sub@fig:ae3-results-pong}{{c}{51}{Training results for RL agent using pre-trained autoencoder 3 in Pong.\relax }{figure.caption.39}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {3.21}{\ignorespaces Latent representations of three different autoencoders for an observation frame in Pong.\relax }}{51}{figure.caption.39}\protected@file@percent }
\newlabel{fig:ae-results-pong}{{3.21}{51}{Latent representations of three different autoencoders for an observation frame in Pong.\relax }{figure.caption.39}{}}
\citation{mario}
\citation{pca_2010}
\citation{pca_2010}
\citation{AE_2010}
\citation{AE_2016}
\citation{AE_2019}
\@writefile{toc}{\contentsline {chapter}{\numberline {4}Related work}{52}{chapter.4}\protected@file@percent }
\@writefile{lof}{\addvspace {10\p@ }}
\@writefile{lot}{\addvspace {10\p@ }}
\newlabel{relatedwork}{{4}{52}{Related work}{chapter.4}{}}
\citation{deepmdp}
\bibstyle{plain}
\bibdata{bibliography}
\@writefile{toc}{\contentsline {chapter}{\numberline {5}Conclusions and future research}{54}{chapter.5}\protected@file@percent }
\@writefile{lof}{\addvspace {10\p@ }}
\@writefile{lot}{\addvspace {10\p@ }}
\newlabel{conclusions}{{5}{54}{Conclusions and future research}{chapter.5}{}}
\bibcite{pca_2010}{1}
\bibcite{blizzard}{2}
\bibcite{pong}{3}
\bibcite{mario}{4}
\bibcite{transpose}{5}
\bibcite{deepmdp}{6}
\bibcite{nn}{7}
\bibcite{wgan}{8}
\bibcite{gelu}{9}
\bibcite{AE_general}{10}
\bibcite{tsne}{11}
\bibcite{batchnorm}{12}
\bibcite{CNN_computation}{13}
\bibcite{qlearning}{14}
\bibcite{pca}{15}
\bibcite{adam}{16}
\bibcite{AE_2010}{17}
\bibcite{deeprl}{18}
\bibcite{dqn}{19}
\bibcite{grokking}{20}
\bibcite{relu}{21}
\bibcite{l1}{22}
\bibcite{AE_2019}{23}
\bibcite{maxvsconv}{24}
\bibcite{ddqn}{25}
\bibcite{AE_2016}{26}
\bibcite{pysc2}{27}
\bibcite{rlfitting}{28}
\citation{transpose}
\citation{relu}
\@writefile{toc}{\contentsline {chapter}{\numberline {A}Appendix}{58}{appendix.A}\protected@file@percent }
\@writefile{lof}{\addvspace {10\p@ }}
\@writefile{lot}{\addvspace {10\p@ }}
\newlabel{appendix}{{A}{58}{Appendix}{appendix.A}{}}
\@writefile{toc}{\contentsline {section}{\numberline {A.1}Starcraft II: RL agent architectures}{58}{section.A.1}\protected@file@percent }
\newlabel{appendix-agents}{{A.1}{58}{Starcraft II: RL agent architectures}{section.A.1}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {A.1.1}Baseline agent}{58}{subsection.A.1.1}\protected@file@percent }
\newlabel{appendix-baseline}{{A.1.1}{58}{Baseline agent}{subsection.A.1.1}{}}
\citation{adam}
\citation{gelu}
\@writefile{toc}{\contentsline {subsection}{\numberline {A.1.2}PCA agent}{59}{subsection.A.1.2}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {A.1.3}Pre-trained and online trained autoencoder agent}{59}{subsection.A.1.3}\protected@file@percent }
\@writefile{lof}{\contentsline {figure}{\numberline {A.1}{\ignorespaces The decay of the epsilon value per episode.\relax }}{60}{figure.caption.41}\protected@file@percent }
\newlabel{fig:epsilon}{{A.1}{60}{The decay of the epsilon value per episode.\relax }{figure.caption.41}{}}
\citation{l1}
\citation{wgan}
\@writefile{toc}{\contentsline {subsection}{\numberline {A.1.4}DeepMDP agent}{61}{subsection.A.1.4}\protected@file@percent }
\@writefile{toc}{\contentsline {section}{\numberline {A.2}OpenAI Pong: RL agent architectures}{61}{section.A.2}\protected@file@percent }
\newlabel{appendix-agents-pong}{{A.2}{61}{OpenAI Pong: RL agent architectures}{section.A.2}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {A.2.1}Baseline agent}{61}{subsection.A.2.1}\protected@file@percent }
\newlabel{appendix-baseline-pong}{{A.2.1}{61}{Baseline agent}{subsection.A.2.1}{}}
\citation{batchnorm}
\citation{relu}
\citation{adam}
\@writefile{toc}{\contentsline {subsection}{\numberline {A.2.2}PCA agent}{62}{subsection.A.2.2}\protected@file@percent }
\citation{gelu}
\@writefile{lof}{\contentsline {figure}{\numberline {A.2}{\ignorespaces The decay of the epsilon value per episode in Pong.\relax }}{63}{figure.caption.42}\protected@file@percent }
\newlabel{fig:epsilon-pong}{{A.2}{63}{The decay of the epsilon value per episode in Pong.\relax }{figure.caption.42}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {A.2.3}Pre-trained and online trained autoencoder agent}{63}{subsection.A.2.3}\protected@file@percent }
