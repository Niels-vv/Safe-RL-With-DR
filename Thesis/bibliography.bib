@misc{blizzard, title={Blizzard/s2client-proto: StarCraft {II} {Client} - protocol definitions used to communicate with {StarCraft II}.}, url={https://github.com/Blizzard/s2client-proto}, journal={GitHub}, author={Blizzard}} 

@article{pysc2,
  author    = {Oriol Vinyals and
               Timo Ewalds and
               Sergey Bartunov and
               Petko Georgiev and
               Alexander Sasha Vezhnevets and
               Michelle Yeo and
               Alireza Makhzani and
               Heinrich K{\"{u}}ttler and
               John P. Agapiou and
               Julian Schrittwieser and
               John Quan and
               Stephen Gaffney and
               Stig Petersen and
               Karen Simonyan and
               Tom Schaul and
               Hado van Hasselt and
               David Silver and
               Timothy P. Lillicrap and
               Kevin Calderone and
               Paul Keet and
               Anthony Brunasso and
               David Lawrence and
               Anders Ekermo and
               Jacob Repp and
               Rodney Tsing},
  title     = {{StarCraft II:} {A} New Challenge for Reinforcement Learning},
  journal   = {CoRR},
  volume    = {abs/1708.04782},
  year      = {2017},
  url       = {http://arxiv.org/abs/1708.04782},
  eprinttype = {arXiv},
  eprint    = {1708.04782},
  timestamp = {Sat, 23 Jan 2021 01:20:55 +0100},
  biburl    = {https://dblp.org/rec/journals/corr/abs-1708-04782.bib},
  bibsource = {dblp computer science bibliography, https://dblp.org}
}

@article{AE_general,
author = {G. E. Hinton  and R. R. Salakhutdinov },
title = {Reducing the Dimensionality of Data with Neural Networks},
journal = {Science},
volume = {313},
number = {5786},
pages = {504-507},
year = {2006},
doi = {10.1126/science.1127647},

URL = {https://www.science.org/doi/abs/10.1126/science.1127647},
eprint = {https://www.science.org/doi/pdf/10.1126/science.1127647}
,
    abstract = { High-dimensional data can be converted to low-dimensional codes by training a multilayer neural network with a small central layer to reconstruct high-dimensional input vectors. Gradient descent can be used for fine-tuning the weights in such “autoencoder” networks, but this works well only if the initial weights are close to a good solution. We describe an effective way of initializing the weights that allows deep autoencoder networks to learn low-dimensional codes that work much better than principal components analysis as a tool to reduce the dimensionality of data. }
}

@article{grokking,
  author = {Morales, Miguel},
  editor = {Co., Manning Publications},
  title = {Grokking Deep Reinforcement Learning},
  year = 2020
}

@book{nn,
    title={Deep Learning},
    author={Ian Goodfellow and Yoshua Bengio and Aaron Courville},
    publisher={MIT Press},
    note={\url{http://www.deeplearningbook.org}},
    year={2016}
}

@article{dqn,
  added-at = {2015-08-26T14:46:40.000+0200},
  author = {Mnih, Volodymyr and Kavukcuoglu, Koray and Silver, David and Rusu, Andrei A. and Veness, Joel and Bellemare, Marc G. and Graves, Alex and Riedmiller, Martin and Fidjeland, Andreas K. and Ostrovski, Georg and Petersen, Stig and Beattie, Charles and Sadik, Amir and Antonoglou, Ioannis and King, Helen and Kumaran, Dharshan and Wierstra, Daan and Legg, Shane and Hassabis, Demis},
  biburl = {https://www.bibsonomy.org/bibtex/2fb15f4471c81dc2b9edf2304cb2f7083/hotho},
  description = {Human-level control through deep reinforcement learning - nature14236.pdf},
  interhash = {eac59980357d99db87b341b61ef6645f},
  intrahash = {fb15f4471c81dc2b9edf2304cb2f7083},
  issn = {00280836},
  journal = {Nature},
  keywords = {deep learning toread},
  month = feb,
  number = 7540,
  pages = {529--533},
  publisher = {Nature Publishing Group, a division of Macmillan Publishers Limited. All Rights Reserved.},
  timestamp = {2015-08-26T14:46:40.000+0200},
  title = {Human-level control through deep reinforcement learning},
  url = {http://dx.doi.org/10.1038/nature14236},
  volume = 518,
  year = 2015
}

@article{ddqn,
  added-at = {2019-11-18T11:40:13.000+0100},
  author = {van Hasselt, Hado and Guez, Arthur and Silver, David},
  biburl = {https://www.bibsonomy.org/bibtex/2c2bad4b4c5a34cb31a3f569c71e851ab/jan.hofmann1},
  description = {[1509.06461] Deep Reinforcement Learning with Double Q-learning},
  interhash = {d3061c37961afb78096e314854dd90bc},
  intrahash = {c2bad4b4c5a34cb31a3f569c71e851ab},
  keywords = {dqn final q-learning reinforcement_learning thema:double_dqn},
  note = {cite arxiv:1509.06461Comment: AAAI 2016},
  timestamp = {2019-12-09T10:13:49.000+0100},
  title = {Deep Reinforcement Learning with Double Q-learning},
  url = {http://arxiv.org/abs/1509.06461},
  year = 2015
}

@article{qlearning,
author = {Jang, Beakcheol and Kim, Myeonghwi and Harerimana, Gaspard and Kim, Jong},
year = {2019},
month = {09},
pages = {1-1},
title = {Q-Learning Algorithms: A Comprehensive Classification and Applications},
volume = {PP},
journal = {IEEE Access},
doi = {10.1109/ACCESS.2019.2941229}
}